{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple binary classifier for stock movements\n",
    "### Author: Niklas Walter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we present a simple method to predict high-frequency price changes of an undisclosed US stock based on Limit Order Book (LOB) data and past move directions. For simplicity we only consider binary movements, meaning that we do not care about the size of a tick but only its directions. In particular, we label an upward move of the midprice by $1$ and a downward move by $0$, where the midprice is defined as\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\text{midprice} = \\frac{\\text{bid price} + \\text{ask price}}{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "To make a predicition we use a neural network implemented using `Keras`. As training data `(\"Dataset_A.csv\")` we use the volume and price data from the LOB. In particular, we consider Level 1 and Level 2, where the first one represents the most competitive price respectively and the second the second most competitive order positions. Moreover, we have knowledge about the last five move directions of the stock. The rows of this file have been randomly drawn from a larger data set, and they can be treated as 100,000 iid samples. Hence, no time series structure can be recovered from the data. While we use this first labeled dataset for training and validation purposes, our goal is to make predictions based on the unlabeled data stored in `(\"Dataset_B_nolabels.csv\")`.\n",
    "\n",
    "Data on high-frequency stock data can for example be found under https://lobsterdata.com .\n",
    "\n",
    "The notebook is organised as follows. First, we make some simple analyses on the data set to get a first feeling for the data. Secondly, we want to find the optimal architeture for the neural network. Note that the choice is in the end mostly based on the errors of the training and validation epochs. Lastly, we implement the network and run the prediction on the unlabled dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Analysing and manipulating the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step, we import the data from a .csv file into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Dataset_A.csv\", names = [\"Actual Move Direction\", \"Sell Side Price LV1\", \"Sell Side Volume LV1\", \"Buy Side Price LV1\", \"Buy Side Volume LV1\", \"Sell Side Price LV2\", \"Sell Side Volume LV2\", \"Buy Side Price LV2\", \"Buy Side Volume LV2\", \"Past Move 1\", \"Past Move 2\", \"Past Move 3\", \"Past Move 4\", \"Past Move 5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Move Direction</th>\n",
       "      <th>Sell Side Price LV1</th>\n",
       "      <th>Sell Side Volume LV1</th>\n",
       "      <th>Buy Side Price LV1</th>\n",
       "      <th>Buy Side Volume LV1</th>\n",
       "      <th>Sell Side Price LV2</th>\n",
       "      <th>Sell Side Volume LV2</th>\n",
       "      <th>Buy Side Price LV2</th>\n",
       "      <th>Buy Side Volume LV2</th>\n",
       "      <th>Past Move 1</th>\n",
       "      <th>Past Move 2</th>\n",
       "      <th>Past Move 3</th>\n",
       "      <th>Past Move 4</th>\n",
       "      <th>Past Move 5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observations</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>369900</td>\n",
       "      <td>1043</td>\n",
       "      <td>369800</td>\n",
       "      <td>100</td>\n",
       "      <td>370000</td>\n",
       "      <td>1443</td>\n",
       "      <td>369700</td>\n",
       "      <td>846</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>361800</td>\n",
       "      <td>22721</td>\n",
       "      <td>361600</td>\n",
       "      <td>8875</td>\n",
       "      <td>361900</td>\n",
       "      <td>6835</td>\n",
       "      <td>361500</td>\n",
       "      <td>6068</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>356900</td>\n",
       "      <td>100</td>\n",
       "      <td>356800</td>\n",
       "      <td>1200</td>\n",
       "      <td>357000</td>\n",
       "      <td>500</td>\n",
       "      <td>356700</td>\n",
       "      <td>1056</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>362100</td>\n",
       "      <td>3500</td>\n",
       "      <td>362000</td>\n",
       "      <td>200</td>\n",
       "      <td>362200</td>\n",
       "      <td>7036</td>\n",
       "      <td>361900</td>\n",
       "      <td>3373</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>353600</td>\n",
       "      <td>13946</td>\n",
       "      <td>353400</td>\n",
       "      <td>9739</td>\n",
       "      <td>353700</td>\n",
       "      <td>13885</td>\n",
       "      <td>353300</td>\n",
       "      <td>12701</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "      <td>363300</td>\n",
       "      <td>19811</td>\n",
       "      <td>363200</td>\n",
       "      <td>100</td>\n",
       "      <td>363400</td>\n",
       "      <td>15558</td>\n",
       "      <td>363100</td>\n",
       "      <td>5015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>378100</td>\n",
       "      <td>4110</td>\n",
       "      <td>377900</td>\n",
       "      <td>2345</td>\n",
       "      <td>378200</td>\n",
       "      <td>2045</td>\n",
       "      <td>377800</td>\n",
       "      <td>1645</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1</td>\n",
       "      <td>362800</td>\n",
       "      <td>200</td>\n",
       "      <td>362700</td>\n",
       "      <td>1200</td>\n",
       "      <td>362900</td>\n",
       "      <td>1600</td>\n",
       "      <td>362600</td>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1</td>\n",
       "      <td>365200</td>\n",
       "      <td>14604</td>\n",
       "      <td>365000</td>\n",
       "      <td>21577</td>\n",
       "      <td>365300</td>\n",
       "      <td>24933</td>\n",
       "      <td>364900</td>\n",
       "      <td>19197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>1</td>\n",
       "      <td>365500</td>\n",
       "      <td>500</td>\n",
       "      <td>365400</td>\n",
       "      <td>800</td>\n",
       "      <td>365600</td>\n",
       "      <td>1200</td>\n",
       "      <td>365300</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Actual Move Direction  Sell Side Price LV1  \\\n",
       "Observations                                               \n",
       "1                                 0               369900   \n",
       "2                                 0               361800   \n",
       "3                                 1               356900   \n",
       "4                                 0               362100   \n",
       "5                                 0               353600   \n",
       "...                             ...                  ...   \n",
       "99996                             0               363300   \n",
       "99997                             0               378100   \n",
       "99998                             1               362800   \n",
       "99999                             1               365200   \n",
       "100000                            1               365500   \n",
       "\n",
       "              Sell Side Volume LV1  Buy Side Price LV1  Buy Side Volume LV1  \\\n",
       "Observations                                                                  \n",
       "1                             1043              369800                  100   \n",
       "2                            22721              361600                 8875   \n",
       "3                              100              356800                 1200   \n",
       "4                             3500              362000                  200   \n",
       "5                            13946              353400                 9739   \n",
       "...                            ...                 ...                  ...   \n",
       "99996                        19811              363200                  100   \n",
       "99997                         4110              377900                 2345   \n",
       "99998                          200              362700                 1200   \n",
       "99999                        14604              365000                21577   \n",
       "100000                         500              365400                  800   \n",
       "\n",
       "              Sell Side Price LV2  Sell Side Volume LV2  Buy Side Price LV2  \\\n",
       "Observations                                                                  \n",
       "1                          370000                  1443              369700   \n",
       "2                          361900                  6835              361500   \n",
       "3                          357000                   500              356700   \n",
       "4                          362200                  7036              361900   \n",
       "5                          353700                 13885              353300   \n",
       "...                           ...                   ...                 ...   \n",
       "99996                      363400                 15558              363100   \n",
       "99997                      378200                  2045              377800   \n",
       "99998                      362900                  1600              362600   \n",
       "99999                      365300                 24933              364900   \n",
       "100000                     365600                  1200              365300   \n",
       "\n",
       "              Buy Side Volume LV2  Past Move 1  Past Move 2  Past Move 3  \\\n",
       "Observations                                                               \n",
       "1                             846            1            0            0   \n",
       "2                            6068            0            0            0   \n",
       "3                            1056            1            0            1   \n",
       "4                            3373            0            0            1   \n",
       "5                           12701            0            1            0   \n",
       "...                           ...          ...          ...          ...   \n",
       "99996                        5015            0            0            0   \n",
       "99997                        1645            0            1            0   \n",
       "99998                         915            0            0            0   \n",
       "99999                       19197            1            0            1   \n",
       "100000                        800            0            1            0   \n",
       "\n",
       "              Past Move 4  Past Move 5  \n",
       "Observations                            \n",
       "1                       0            1  \n",
       "2                       0            0  \n",
       "3                       0            0  \n",
       "4                       1            0  \n",
       "5                       1            1  \n",
       "...                   ...          ...  \n",
       "99996                   0            0  \n",
       "99997                   0            0  \n",
       "99998                   0            0  \n",
       "99999                   0            1  \n",
       "100000                  0            1  \n",
       "\n",
       "[100000 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.set_index(np.linspace(1,100000,100000).astype(int))\n",
    "data.index.name = 'Observations'\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a first step, we only look at the five past moves and want to see how good the direction of a next move can be predicted using a weighted average of the former moves. The idea behind this is the assumption that the last jump direction contains more information about the next one, than the second last move and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Move Direction</th>\n",
       "      <th>Past Move 1</th>\n",
       "      <th>Past Move 2</th>\n",
       "      <th>Past Move 3</th>\n",
       "      <th>Past Move 4</th>\n",
       "      <th>Past Move 5</th>\n",
       "      <th>Past Moves Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Actual Move Direction  Past Move 1  Past Move 2  Past Move 3  \\\n",
       "1                           0            1            0            0   \n",
       "2                           0            0            0            0   \n",
       "3                           1            1            0            1   \n",
       "4                           0            0            0            1   \n",
       "5                           0            0            1            0   \n",
       "...                       ...          ...          ...          ...   \n",
       "99996                       0            0            0            0   \n",
       "99997                       0            0            1            0   \n",
       "99998                       1            0            0            0   \n",
       "99999                       1            1            0            1   \n",
       "100000                      1            0            1            0   \n",
       "\n",
       "        Past Move 4  Past Move 5  Past Moves Prediction  \n",
       "1                 0            1                      0  \n",
       "2                 0            0                      0  \n",
       "3                 0            0                      0  \n",
       "4                 1            0                      0  \n",
       "5                 1            1                      0  \n",
       "...             ...          ...                    ...  \n",
       "99996             0            0                      0  \n",
       "99997             0            0                      0  \n",
       "99998             0            0                      0  \n",
       "99999             0            1                      0  \n",
       "100000            0            1                      0  \n",
       "\n",
       "[100000 rows x 7 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movements = data.iloc[:,[0,9,10,11,12,13]]\n",
    "predicitions = pd.DataFrame(np.round(np.average(movements.iloc[:,[1,2,3,4,5]], axis = 1, weights = (1./15, 2./15, 3./15, 4./15, 5./15)).astype(int)), columns = [\"Past Moves Prediction\"])\n",
    "predicitions = predicitions.set_index(np.linspace(1,100000,100000).astype(int))\n",
    "movements = pd.concat([movements, predicitions], axis = 1)\n",
    "movements = movements.set_index(np.linspace(1,100000,100000).astype(int))\n",
    "movements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple computation shows that the accuracy of this method is pretty low. In fact, in the end the prediction is only as good as a coin toss. Therefore, building a network only taking the past moves as input does not look like a promising strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 51.68%\n"
     ]
    }
   ],
   "source": [
    "test = np.abs(movements[\"Actual Move Direction\"] - movements[\"Past Moves Prediction\"])\n",
    "print(\"Accuracy: \" + str(np.round(100*(1.0 - np.sum(test)/len(movements[\"Actual Move Direction\"])),2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to use the volumes in the LOB to explain the next move direction. For this we consider both only the volume at Level 1 and the volume at Level 1 and 2 combined. Then the idea is that the volume imbalance defined as \n",
    "\n",
    "$$\n",
    "    I_t := \\frac{V^b_t}{V^a_t + V^b_t}\n",
    "$$\n",
    "\n",
    "at some time $t$, where $V^a_t$ is the volume at time $t$ on the sell (ask) side and $V^b_t$ on the buy (bid) side. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sell Side Volume LV1</th>\n",
       "      <th>Buy Side Volume LV1</th>\n",
       "      <th>Total Sell Side Volume</th>\n",
       "      <th>Total Buy Side Volume</th>\n",
       "      <th>Volume Order Imbalance Level 1</th>\n",
       "      <th>Volume Order Imbalance Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1043</td>\n",
       "      <td>100</td>\n",
       "      <td>2486</td>\n",
       "      <td>946</td>\n",
       "      <td>0.087489</td>\n",
       "      <td>0.275641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22721</td>\n",
       "      <td>8875</td>\n",
       "      <td>29556</td>\n",
       "      <td>14943</td>\n",
       "      <td>0.280890</td>\n",
       "      <td>0.335805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>1200</td>\n",
       "      <td>600</td>\n",
       "      <td>2256</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.789916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3500</td>\n",
       "      <td>200</td>\n",
       "      <td>10536</td>\n",
       "      <td>3573</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.253243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13946</td>\n",
       "      <td>9739</td>\n",
       "      <td>27831</td>\n",
       "      <td>22440</td>\n",
       "      <td>0.411189</td>\n",
       "      <td>0.446381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>19811</td>\n",
       "      <td>100</td>\n",
       "      <td>35369</td>\n",
       "      <td>5115</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.126346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>4110</td>\n",
       "      <td>2345</td>\n",
       "      <td>6155</td>\n",
       "      <td>3990</td>\n",
       "      <td>0.363284</td>\n",
       "      <td>0.393297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>200</td>\n",
       "      <td>1200</td>\n",
       "      <td>1800</td>\n",
       "      <td>2115</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.540230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>14604</td>\n",
       "      <td>21577</td>\n",
       "      <td>39537</td>\n",
       "      <td>40774</td>\n",
       "      <td>0.596363</td>\n",
       "      <td>0.507701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>500</td>\n",
       "      <td>800</td>\n",
       "      <td>1700</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sell Side Volume LV1  Buy Side Volume LV1  Total Sell Side Volume  \\\n",
       "1                       1043                  100                    2486   \n",
       "2                      22721                 8875                   29556   \n",
       "3                        100                 1200                     600   \n",
       "4                       3500                  200                   10536   \n",
       "5                      13946                 9739                   27831   \n",
       "...                      ...                  ...                     ...   \n",
       "99996                  19811                  100                   35369   \n",
       "99997                   4110                 2345                    6155   \n",
       "99998                    200                 1200                    1800   \n",
       "99999                  14604                21577                   39537   \n",
       "100000                   500                  800                    1700   \n",
       "\n",
       "        Total Buy Side Volume  Volume Order Imbalance Level 1  \\\n",
       "1                         946                        0.087489   \n",
       "2                       14943                        0.280890   \n",
       "3                        2256                        0.923077   \n",
       "4                        3573                        0.054054   \n",
       "5                       22440                        0.411189   \n",
       "...                       ...                             ...   \n",
       "99996                    5115                        0.005022   \n",
       "99997                    3990                        0.363284   \n",
       "99998                    2115                        0.857143   \n",
       "99999                   40774                        0.596363   \n",
       "100000                   1600                        0.615385   \n",
       "\n",
       "        Volume Order Imbalance Total  \n",
       "1                           0.275641  \n",
       "2                           0.335805  \n",
       "3                           0.789916  \n",
       "4                           0.253243  \n",
       "5                           0.446381  \n",
       "...                              ...  \n",
       "99996                       0.126346  \n",
       "99997                       0.393297  \n",
       "99998                       0.540230  \n",
       "99999                       0.507701  \n",
       "100000                      0.484848  \n",
       "\n",
       "[100000 rows x 6 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_volume_sell_side = pd.DataFrame(data[\"Sell Side Volume LV1\"] + data[\"Sell Side Volume LV2\"], columns = [\"Total Sell Side Volume\"])\n",
    "total_volume_sell_side = total_volume_sell_side.set_index(movements.index)\n",
    "total_volume_buy_side = pd.DataFrame(data[\"Buy Side Volume LV1\"] + data[\"Buy Side Volume LV2\"], columns = [\"Total Buy Side Volume\"])\n",
    "total_volume_buy_side = total_volume_buy_side.set_index(movements.index)\n",
    "volume_imb_lv1 = pd.DataFrame(data[\"Buy Side Volume LV1\"].to_numpy() / (data[\"Buy Side Volume LV1\"].to_numpy() + data[\"Sell Side Volume LV1\"].to_numpy()), columns = [\"Volume Order Imbalance Level 1\"])\n",
    "volume_imb_lv1 = volume_imb_lv1.set_index(movements.index)\n",
    "total_volume_imb = pd.DataFrame(total_volume_buy_side.to_numpy()/(total_volume_buy_side.to_numpy() + total_volume_sell_side.to_numpy()), columns = [\"Volume Order Imbalance Total\"])\n",
    "total_volume_imb = total_volume_imb.set_index(movements.index)\n",
    "total_volumes = pd.concat([pd.DataFrame(data[\"Sell Side Volume LV1\"]), pd.DataFrame(data[\"Buy Side Volume LV1\"]), total_volume_sell_side, total_volume_buy_side, volume_imb_lv1 , total_volume_imb], axis = 1)\n",
    "total_volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the case $I_t > 0.5 $, there are is more volume on the buy side than on the sell side. Thus from a basic economical idea it is more likely that prices will go up. So we introduce the following prediction $\\hat{y}_t$ for the next jump direction\n",
    "\n",
    "$$\n",
    "\\hat{y}_t = \n",
    "\\begin{cases} \n",
    "    1\\; \\text{if } I_t > 0.5 \\\\\n",
    "    0\\; \\text{else} \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Move Direction</th>\n",
       "      <th>Past Move 1</th>\n",
       "      <th>Past Move 2</th>\n",
       "      <th>Past Move 3</th>\n",
       "      <th>Past Move 4</th>\n",
       "      <th>Past Move 5</th>\n",
       "      <th>Past Moves Prediction</th>\n",
       "      <th>Volume Order Imbalance Level 1 Prediction</th>\n",
       "      <th>Volume Order Imbalance Total Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Actual Move Direction  Past Move 1  Past Move 2  Past Move 3  \\\n",
       "1                           0            1            0            0   \n",
       "2                           0            0            0            0   \n",
       "3                           1            1            0            1   \n",
       "4                           0            0            0            1   \n",
       "5                           0            0            1            0   \n",
       "...                       ...          ...          ...          ...   \n",
       "99996                       0            0            0            0   \n",
       "99997                       0            0            1            0   \n",
       "99998                       1            0            0            0   \n",
       "99999                       1            1            0            1   \n",
       "100000                      1            0            1            0   \n",
       "\n",
       "        Past Move 4  Past Move 5  Past Moves Prediction  \\\n",
       "1                 0            1                      0   \n",
       "2                 0            0                      0   \n",
       "3                 0            0                      0   \n",
       "4                 1            0                      0   \n",
       "5                 1            1                      0   \n",
       "...             ...          ...                    ...   \n",
       "99996             0            0                      0   \n",
       "99997             0            0                      0   \n",
       "99998             0            0                      0   \n",
       "99999             0            1                      0   \n",
       "100000            0            1                      0   \n",
       "\n",
       "        Volume Order Imbalance Level 1 Prediction  \\\n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               1   \n",
       "4                                               0   \n",
       "5                                               0   \n",
       "...                                           ...   \n",
       "99996                                           0   \n",
       "99997                                           0   \n",
       "99998                                           1   \n",
       "99999                                           1   \n",
       "100000                                          1   \n",
       "\n",
       "        Volume Order Imbalance Total Prediction  \n",
       "1                                             0  \n",
       "2                                             0  \n",
       "3                                             1  \n",
       "4                                             0  \n",
       "5                                             0  \n",
       "...                                         ...  \n",
       "99996                                         0  \n",
       "99997                                         0  \n",
       "99998                                         1  \n",
       "99999                                         1  \n",
       "100000                                        0  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2 = pd.DataFrame([1 if imbalance > 0.5 else 0 for imbalance in volume_diff_lv1.to_numpy()], columns=[\"Volume Order Imbalance Level 1 Prediction\"])\n",
    "predictions2 = predictions2.set_index(movements.index)\n",
    "predictions3 = pd.DataFrame([1 if imbalance > 0.5 else 0 for imbalance in total_volume_diff.to_numpy()], columns = [\"Volume Order Imbalance Total Prediction\"])\n",
    "predictions3 = predictions3.set_index(movements.index)\n",
    "movements = pd.concat([movements, predictions2, predictions3], axis = 1)\n",
    "movements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two computations show that for our data sample the direction of the next jump can indeed be pretty good explained by the volume imbalance in the LOB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.38%\n"
     ]
    }
   ],
   "source": [
    "test = np.abs(movements[\"Actual Move Direction\"] - movements[\"Volume Order Imbalance Level 1 Prediction\"])\n",
    "print(\"Accuracy: \" + str(np.round(100*(1.0 - np.sum(test)/len(movements[\"Actual Move Direction\"])),2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.81%\n"
     ]
    }
   ],
   "source": [
    "test = np.abs(movements[\"Actual Move Direction\"] - movements[\"Volume Order Imbalance Total Prediction\"])\n",
    "print(\"Accuracy: \" + str(np.round(100*(1.0 - np.sum(test)/len(movements[\"Actual Move Direction\"])),2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we construct a last approach to predict the next move due to the fact that by intuition we do not want our prediction to be only based on two quantities. Therefore, we give it a try to model it by a mix of our volume based approach and a weighted average of the past moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Move Direction</th>\n",
       "      <th>Past Move 1</th>\n",
       "      <th>Past Move 2</th>\n",
       "      <th>Past Move 3</th>\n",
       "      <th>Past Move 4</th>\n",
       "      <th>Past Move 5</th>\n",
       "      <th>Past Moves Prediction</th>\n",
       "      <th>Volume Order Imbalance Level 1 Prediction</th>\n",
       "      <th>Volume Order Imbalance Total Prediction</th>\n",
       "      <th>Mixed Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Actual Move Direction  Past Move 1  Past Move 2  Past Move 3  \\\n",
       "1                           0            1            0            0   \n",
       "2                           0            0            0            0   \n",
       "3                           1            1            0            1   \n",
       "4                           0            0            0            1   \n",
       "5                           0            0            1            0   \n",
       "...                       ...          ...          ...          ...   \n",
       "99996                       0            0            0            0   \n",
       "99997                       0            0            1            0   \n",
       "99998                       1            0            0            0   \n",
       "99999                       1            1            0            1   \n",
       "100000                      1            0            1            0   \n",
       "\n",
       "        Past Move 4  Past Move 5  Past Moves Prediction  \\\n",
       "1                 0            1                      0   \n",
       "2                 0            0                      0   \n",
       "3                 0            0                      0   \n",
       "4                 1            0                      0   \n",
       "5                 1            1                      0   \n",
       "...             ...          ...                    ...   \n",
       "99996             0            0                      0   \n",
       "99997             0            0                      0   \n",
       "99998             0            0                      0   \n",
       "99999             0            1                      0   \n",
       "100000            0            1                      0   \n",
       "\n",
       "        Volume Order Imbalance Level 1 Prediction  \\\n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               1   \n",
       "4                                               0   \n",
       "5                                               0   \n",
       "...                                           ...   \n",
       "99996                                           0   \n",
       "99997                                           0   \n",
       "99998                                           1   \n",
       "99999                                           1   \n",
       "100000                                          1   \n",
       "\n",
       "        Volume Order Imbalance Total Prediction  Mixed Prediction  \n",
       "1                                             0                 0  \n",
       "2                                             0                 0  \n",
       "3                                             1                 1  \n",
       "4                                             0                 0  \n",
       "5                                             0                 0  \n",
       "...                                         ...               ...  \n",
       "99996                                         0                 0  \n",
       "99997                                         0                 0  \n",
       "99998                                         1                 0  \n",
       "99999                                         1                 1  \n",
       "100000                                        0                 0  \n",
       "\n",
       "[100000 rows x 10 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_prediction = pd.DataFrame(np.round(2./3 * np.average(movements.iloc[:,[1,2,3,4,5]], axis = 1, weights = (1./15, 2./15, 3./15, 4./15, 5./15)) + 1./3 * movements[\"Volume Order Imbalance Total Prediction\"]).to_numpy().astype(int), columns = [\"Mixed Prediction\"])\n",
    "mixed_prediction = mixed_prediction.set_index(np.linspace(1,100000,100000).astype(int))\n",
    "movements = pd.concat([movements, mixed_prediction], axis = 1)\n",
    "movements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this technique does lead to an improvement to the one only considering the former jump directions. However, it worsens the last two approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.72%\n"
     ]
    }
   ],
   "source": [
    "test = np.abs(movements[\"Actual Move Direction\"] - movements[\"Mixed Prediction\"])\n",
    "print(\"Accuracy: \" + str(np.round(100*(1.0 - np.sum(test) / len(movements[\"Actual Move Direction\"])),2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the notebook, we want to define the optimal network architecture by using high-level analyses. Firstly, our goal is to find the optimal amount of input variables, where we distinguish two cases based on our results from the last section:\n",
    "1. Take the volumes of the buy and sell side and the information of the past moves.\n",
    "2. Only take the volumes of the buy and sell side.\n",
    "Here our main concern is that the first approach could lead to overfitting, which would be indicated by the validation error for the regarding model. \n",
    "Secondly, we are interested to find a proper number of neurons for the layers of the network. This means to find a good trade of between accuracy and computation time as well as regrading overfitting again. \n",
    "\n",
    "Moreover, we study the difference between using a ReLU and a Leaky-ReLU activation. Recall at this point that the latter overcomes the drawback of the ReLU activation function of setting all negative values to zero which makes differentiating impossible. \n",
    "\n",
    "Laslty, note that we normalise the order volume data to make training easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7169\n"
     ]
    }
   ],
   "source": [
    "avg = np.mean([np.mean(data[\"Sell Side Volume LV1\"]), np.mean(data[\"Buy Side Volume LV1\"]), np.mean(data[\"Sell Side Volume LV2\"]), np.mean(data[\"Buy Side Volume LV2\"])])\n",
    "print(int(round(avg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Analysis with ReLU activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define the network input variables, we need to normalise and reshape them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(data.index)\n",
    "input1 = np.reshape([data[\"Sell Side Volume LV1\"].to_numpy()],(N,1)) / avg \n",
    "input2 = np.reshape([data[\"Buy Side Volume LV1\"].to_numpy()],(N,1)) / avg \n",
    "input3 = np.reshape([data[\"Sell Side Volume LV2\"].to_numpy()],(N,1)) / avg \n",
    "input4 = np.reshape([data[\"Buy Side Volume LV2\"].to_numpy()],(N,1)) / avg \n",
    "input5 = np.reshape([data[\"Past Move 1\"].to_numpy()],(N,1)) \n",
    "input6 = np.reshape([data[\"Past Move 2\"].to_numpy()],(N,1)) \n",
    "input7 = np.reshape([data[\"Past Move 3\"].to_numpy()],(N,1)) \n",
    "input8 = np.reshape([data[\"Past Move 4\"].to_numpy()],(N,1)) \n",
    "input9 = np.reshape([data[\"Past Move 5\"].to_numpy()],(N,1))\n",
    "X = np.concatenate((input1, input2, input3, input4, input5, input6, input7, input8, input9), axis=1) \n",
    "X2 = np.concatenate((input1, input2, input3, input4), axis=1) \n",
    "Y = np.reshape([data[\"Actual Move Direction\"].to_numpy()],(N,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `Keras` library, define different fully connetced neutral networks of different numbers of neurons. In particular, each model contains of three hiden layers with ReLU as activation and the Sigmoid function as the output function to ensure that the latter lies within $[0,1]$. \n",
    "To evaluate the model's performance we split the training set in a only training set and a valuation set. For the training we make use of the Adam optimiser algorithm and take the binary crossentropy as our loss function, which is defined as\n",
    "\n",
    "$$\n",
    "\\mathcal{l}(x) := - \\frac{1}{M}\\sum_{i=1}^M y_i \\log({\\hat{y_i}}) + (1-y_i)\\log(\\hat{y_i}),\n",
    "$$\n",
    "\n",
    "where $M$ is the size of the output, $y_i$ is the $i$-th target value and $\\hat{y_i}$ is the $i$-th output value.\n",
    "\n",
    "Finally, we use a batch size of 200. The relatively small number means within each epoch the model parameters are updated $\\approx$ 500 times. This helps the model accuracy convergence by the $7$th epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use the volume data and the information of the past move directions as input variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.5919 - accuracy: 0.6763 - val_loss: 0.4233 - val_accuracy: 0.8390\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8429 - val_loss: 0.3650 - val_accuracy: 0.8481\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8488 - val_loss: 0.3511 - val_accuracy: 0.8513\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8548 - val_loss: 0.3432 - val_accuracy: 0.8535\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8561 - val_loss: 0.3418 - val_accuracy: 0.8534\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8556 - val_loss: 0.3335 - val_accuracy: 0.8556\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3288 - accuracy: 0.8595 - val_loss: 0.3298 - val_accuracy: 0.8564\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8598 - val_loss: 0.3261 - val_accuracy: 0.8573\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3258 - accuracy: 0.8588 - val_loss: 0.3230 - val_accuracy: 0.8577\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3190 - accuracy: 0.8597 - val_loss: 0.3217 - val_accuracy: 0.8591\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5276 - accuracy: 0.7674 - val_loss: 0.3646 - val_accuracy: 0.8507\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8529 - val_loss: 0.3350 - val_accuracy: 0.8564\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.8615 - val_loss: 0.3235 - val_accuracy: 0.8592\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3152 - accuracy: 0.8639 - val_loss: 0.3174 - val_accuracy: 0.8605\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3113 - accuracy: 0.8638 - val_loss: 0.3187 - val_accuracy: 0.8600\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3125 - accuracy: 0.8614 - val_loss: 0.3144 - val_accuracy: 0.8611\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3095 - accuracy: 0.8620 - val_loss: 0.3130 - val_accuracy: 0.8623\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3050 - accuracy: 0.8640 - val_loss: 0.3100 - val_accuracy: 0.8626\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3054 - accuracy: 0.8629 - val_loss: 0.3097 - val_accuracy: 0.8626\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3042 - accuracy: 0.8651 - val_loss: 0.3089 - val_accuracy: 0.8642\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5431 - accuracy: 0.7542 - val_loss: 0.3650 - val_accuracy: 0.8480\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.8514 - val_loss: 0.3329 - val_accuracy: 0.8564\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3197 - accuracy: 0.8616 - val_loss: 0.3207 - val_accuracy: 0.8579\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3165 - accuracy: 0.8602 - val_loss: 0.3148 - val_accuracy: 0.8600\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3122 - accuracy: 0.8601 - val_loss: 0.3157 - val_accuracy: 0.8601\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3093 - accuracy: 0.8622 - val_loss: 0.3094 - val_accuracy: 0.8620\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3083 - accuracy: 0.8605 - val_loss: 0.3099 - val_accuracy: 0.8612\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3015 - accuracy: 0.8652 - val_loss: 0.3070 - val_accuracy: 0.8630\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3014 - accuracy: 0.8648 - val_loss: 0.3074 - val_accuracy: 0.8630\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3055 - accuracy: 0.8624 - val_loss: 0.3086 - val_accuracy: 0.8622\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4863 - accuracy: 0.7856 - val_loss: 0.3343 - val_accuracy: 0.8583\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8630 - val_loss: 0.3167 - val_accuracy: 0.8587\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3149 - accuracy: 0.8602 - val_loss: 0.3158 - val_accuracy: 0.8565\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3035 - accuracy: 0.8629 - val_loss: 0.3102 - val_accuracy: 0.8612\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3057 - accuracy: 0.8628 - val_loss: 0.3062 - val_accuracy: 0.8622\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2965 - accuracy: 0.8660 - val_loss: 0.3114 - val_accuracy: 0.8599\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3010 - accuracy: 0.8633 - val_loss: 0.3033 - val_accuracy: 0.8623\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3004 - accuracy: 0.8635 - val_loss: 0.3034 - val_accuracy: 0.8617\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2975 - accuracy: 0.8657 - val_loss: 0.3059 - val_accuracy: 0.8609\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2999 - accuracy: 0.8637 - val_loss: 0.3008 - val_accuracy: 0.8635\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4524 - accuracy: 0.8166 - val_loss: 0.3331 - val_accuracy: 0.8585\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8586 - val_loss: 0.3140 - val_accuracy: 0.8573\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3085 - accuracy: 0.8610 - val_loss: 0.3086 - val_accuracy: 0.8607\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3063 - accuracy: 0.8638 - val_loss: 0.3052 - val_accuracy: 0.8632\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3001 - accuracy: 0.8651 - val_loss: 0.3066 - val_accuracy: 0.8597\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3014 - accuracy: 0.8656 - val_loss: 0.3048 - val_accuracy: 0.8615\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2996 - accuracy: 0.8634 - val_loss: 0.3039 - val_accuracy: 0.8644\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3019 - accuracy: 0.8638 - val_loss: 0.3141 - val_accuracy: 0.8582\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2960 - accuracy: 0.8649 - val_loss: 0.3021 - val_accuracy: 0.8620\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2978 - accuracy: 0.8638 - val_loss: 0.3027 - val_accuracy: 0.8624\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 5ms/step - loss: 0.4433 - accuracy: 0.8275 - val_loss: 0.3196 - val_accuracy: 0.8601\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3177 - accuracy: 0.8598 - val_loss: 0.3075 - val_accuracy: 0.8642\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3045 - accuracy: 0.8624 - val_loss: 0.3058 - val_accuracy: 0.8628\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3061 - accuracy: 0.8629 - val_loss: 0.3041 - val_accuracy: 0.8631\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2980 - accuracy: 0.8663 - val_loss: 0.3049 - val_accuracy: 0.8609\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2988 - accuracy: 0.8648 - val_loss: 0.3009 - val_accuracy: 0.8632\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3001 - accuracy: 0.8616 - val_loss: 0.3025 - val_accuracy: 0.8629\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2986 - accuracy: 0.8639 - val_loss: 0.3010 - val_accuracy: 0.8641\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2983 - accuracy: 0.8649 - val_loss: 0.3038 - val_accuracy: 0.8602\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.2935 - accuracy: 0.8647 - val_loss: 0.3008 - val_accuracy: 0.8623\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.4222 - accuracy: 0.8283 - val_loss: 0.3213 - val_accuracy: 0.8574\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3119 - accuracy: 0.8622 - val_loss: 0.3063 - val_accuracy: 0.8633\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3044 - accuracy: 0.8621 - val_loss: 0.3051 - val_accuracy: 0.8622\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3031 - accuracy: 0.8632 - val_loss: 0.3054 - val_accuracy: 0.8609\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.2980 - accuracy: 0.8639 - val_loss: 0.3048 - val_accuracy: 0.8616\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.2955 - accuracy: 0.8647 - val_loss: 0.3037 - val_accuracy: 0.8622\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.2987 - accuracy: 0.8633 - val_loss: 0.2996 - val_accuracy: 0.8642\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.2950 - accuracy: 0.8662 - val_loss: 0.3019 - val_accuracy: 0.8618\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.2957 - accuracy: 0.8658 - val_loss: 0.3004 - val_accuracy: 0.8641\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.2947 - accuracy: 0.8648 - val_loss: 0.2995 - val_accuracy: 0.8629\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 3s 9ms/step - loss: 0.4027 - accuracy: 0.8387 - val_loss: 0.3150 - val_accuracy: 0.8595\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.3083 - accuracy: 0.8619 - val_loss: 0.3042 - val_accuracy: 0.8633\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3059 - accuracy: 0.8592 - val_loss: 0.3040 - val_accuracy: 0.8623\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3045 - accuracy: 0.8607 - val_loss: 0.3007 - val_accuracy: 0.8628\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.2973 - accuracy: 0.8645 - val_loss: 0.3040 - val_accuracy: 0.8626\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.2977 - accuracy: 0.8650 - val_loss: 0.3002 - val_accuracy: 0.8639\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.2936 - accuracy: 0.8666 - val_loss: 0.2992 - val_accuracy: 0.8640\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.2966 - accuracy: 0.8641 - val_loss: 0.3018 - val_accuracy: 0.8630\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.2971 - accuracy: 0.8654 - val_loss: 0.3017 - val_accuracy: 0.8623\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.2930 - accuracy: 0.8655 - val_loss: 0.2999 - val_accuracy: 0.8641\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.3978 - accuracy: 0.8345 - val_loss: 0.3137 - val_accuracy: 0.8618\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3083 - accuracy: 0.8619 - val_loss: 0.3079 - val_accuracy: 0.8622\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3052 - accuracy: 0.8597 - val_loss: 0.3030 - val_accuracy: 0.8642\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.2960 - accuracy: 0.8654 - val_loss: 0.3047 - val_accuracy: 0.8621\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.2995 - accuracy: 0.8632 - val_loss: 0.3050 - val_accuracy: 0.8610\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.3001 - accuracy: 0.8636 - val_loss: 0.2996 - val_accuracy: 0.8649\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.2972 - accuracy: 0.8639 - val_loss: 0.3035 - val_accuracy: 0.8616\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.2985 - accuracy: 0.8630 - val_loss: 0.3033 - val_accuracy: 0.8598\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.2942 - accuracy: 0.8650 - val_loss: 0.3005 - val_accuracy: 0.8634\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.2920 - accuracy: 0.8670 - val_loss: 0.3011 - val_accuracy: 0.8617\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 5s 17ms/step - loss: 0.3947 - accuracy: 0.8387 - val_loss: 0.3170 - val_accuracy: 0.8583\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3114 - accuracy: 0.8619 - val_loss: 0.3083 - val_accuracy: 0.8581\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3029 - accuracy: 0.8626 - val_loss: 0.3092 - val_accuracy: 0.8593\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.2997 - accuracy: 0.8627 - val_loss: 0.3011 - val_accuracy: 0.8634\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.2983 - accuracy: 0.8642 - val_loss: 0.3019 - val_accuracy: 0.8611\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.2992 - accuracy: 0.8638 - val_loss: 0.3021 - val_accuracy: 0.8635\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.2903 - accuracy: 0.8661 - val_loss: 0.3023 - val_accuracy: 0.8635\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.2914 - accuracy: 0.8669 - val_loss: 0.2982 - val_accuracy: 0.8642\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.2912 - accuracy: 0.8675 - val_loss: 0.3050 - val_accuracy: 0.8612\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.2949 - accuracy: 0.8639 - val_loss: 0.2967 - val_accuracy: 0.8651\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.3834 - accuracy: 0.8402 - val_loss: 0.3211 - val_accuracy: 0.8548\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 0.3095 - accuracy: 0.8593 - val_loss: 0.3082 - val_accuracy: 0.8617\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.3003 - accuracy: 0.8633 - val_loss: 0.3089 - val_accuracy: 0.8614\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.3039 - accuracy: 0.8597 - val_loss: 0.3019 - val_accuracy: 0.8621\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.2969 - accuracy: 0.8656 - val_loss: 0.3009 - val_accuracy: 0.8635\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.3010 - accuracy: 0.8624 - val_loss: 0.3033 - val_accuracy: 0.8627\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.2970 - accuracy: 0.8634 - val_loss: 0.3017 - val_accuracy: 0.8634\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.2979 - accuracy: 0.8618 - val_loss: 0.3029 - val_accuracy: 0.8610\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.2912 - accuracy: 0.8675 - val_loss: 0.3005 - val_accuracy: 0.8627\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 0.2911 - accuracy: 0.8662 - val_loss: 0.3026 - val_accuracy: 0.8607\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 7s 26ms/step - loss: 0.3896 - accuracy: 0.8383 - val_loss: 0.3217 - val_accuracy: 0.8551\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 7s 28ms/step - loss: 0.3125 - accuracy: 0.8592 - val_loss: 0.3059 - val_accuracy: 0.8622\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 0.3027 - accuracy: 0.8631 - val_loss: 0.3049 - val_accuracy: 0.8609\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 0.3009 - accuracy: 0.8606 - val_loss: 0.3034 - val_accuracy: 0.8611\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 5s 21ms/step - loss: 0.2998 - accuracy: 0.8628 - val_loss: 0.3018 - val_accuracy: 0.8619\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.2981 - accuracy: 0.8650 - val_loss: 0.2989 - val_accuracy: 0.8634\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 7s 26ms/step - loss: 0.2966 - accuracy: 0.8634 - val_loss: 0.2991 - val_accuracy: 0.8637\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 0.2941 - accuracy: 0.8661 - val_loss: 0.3002 - val_accuracy: 0.8641\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 7s 28ms/step - loss: 0.2910 - accuracy: 0.8659 - val_loss: 0.3005 - val_accuracy: 0.8610\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.2912 - accuracy: 0.8673 - val_loss: 0.2993 - val_accuracy: 0.8633\n"
     ]
    }
   ],
   "source": [
    "parameters = [10, 20, 30, 50, 75, 100, 200, 300, 400, 500, 550, 600]\n",
    "losses = []\n",
    "val_losses = []\n",
    "for para in parameters:\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(para, activation=\"relu\", input_shape=(9,)), \n",
    "        keras.layers.Dense(para, activation=\"relu\"), \n",
    "        keras.layers.Dense(para, activation=\"relu\"), \n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")]\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]) \n",
    "    history = model.fit(X, Y, batch_size=200, epochs=10, validation_split=0.5)\n",
    "    losses.append(history.history['loss'][-1])\n",
    "    val_losses.append(history.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the loss of the training and valuation of the regarding last epoch, indicates that validation error keeps more or less low even for a higher amount of parameters. This indicates that the problem of overfitting is not that high. Moreover, the loss of the training stablises more or less after $100$ neurons per layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(parameters, losses, label = \"Training Error\")\n",
    "plt.plot(parameters, val_losses, label = \"Validation Error\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss Evolution (9 input variables)\")\n",
    "plt.xlabel(\"Amount of neurons in the first three layers\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step, we do the same analysis by only taking the volume data as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5497 - accuracy: 0.7910 - val_loss: 0.4280 - val_accuracy: 0.8459\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4119 - accuracy: 0.8476 - val_loss: 0.3674 - val_accuracy: 0.8508\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3589 - accuracy: 0.8528 - val_loss: 0.3498 - val_accuracy: 0.8506\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8533 - val_loss: 0.3422 - val_accuracy: 0.8507\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8484 - val_loss: 0.3421 - val_accuracy: 0.8478\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8521 - val_loss: 0.3364 - val_accuracy: 0.8516\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.8508 - val_loss: 0.3342 - val_accuracy: 0.8509\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3307 - accuracy: 0.8524 - val_loss: 0.3327 - val_accuracy: 0.8513\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3345 - accuracy: 0.8517 - val_loss: 0.3316 - val_accuracy: 0.8502\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8527 - val_loss: 0.3302 - val_accuracy: 0.8515\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5866 - accuracy: 0.7287 - val_loss: 0.3793 - val_accuracy: 0.8505\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8540 - val_loss: 0.3518 - val_accuracy: 0.8491\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8542 - val_loss: 0.3458 - val_accuracy: 0.8505\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8515 - val_loss: 0.3371 - val_accuracy: 0.8517\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8553 - val_loss: 0.3354 - val_accuracy: 0.8509\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8541 - val_loss: 0.3304 - val_accuracy: 0.8519\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8533 - val_loss: 0.3284 - val_accuracy: 0.8521\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8508 - val_loss: 0.3274 - val_accuracy: 0.8524\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8554 - val_loss: 0.3265 - val_accuracy: 0.8525\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8546 - val_loss: 0.3250 - val_accuracy: 0.8529\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4830 - accuracy: 0.8402 - val_loss: 0.3539 - val_accuracy: 0.8506\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8520 - val_loss: 0.3378 - val_accuracy: 0.8508\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8515 - val_loss: 0.3301 - val_accuracy: 0.8516\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8513 - val_loss: 0.3272 - val_accuracy: 0.8513\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8526 - val_loss: 0.3244 - val_accuracy: 0.8527\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3218 - accuracy: 0.8540 - val_loss: 0.3223 - val_accuracy: 0.8520\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3185 - accuracy: 0.8565 - val_loss: 0.3218 - val_accuracy: 0.8525\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3191 - accuracy: 0.8550 - val_loss: 0.3240 - val_accuracy: 0.8507\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3167 - accuracy: 0.8546 - val_loss: 0.3212 - val_accuracy: 0.8525\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.8543 - val_loss: 0.3200 - val_accuracy: 0.8520\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.8145 - val_loss: 0.3508 - val_accuracy: 0.8514\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3420 - accuracy: 0.8527 - val_loss: 0.3354 - val_accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3369 - accuracy: 0.8507 - val_loss: 0.3331 - val_accuracy: 0.8518\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.8528 - val_loss: 0.3275 - val_accuracy: 0.8517\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3281 - accuracy: 0.8523 - val_loss: 0.3258 - val_accuracy: 0.8508\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8535 - val_loss: 0.3258 - val_accuracy: 0.8505\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3229 - accuracy: 0.8519 - val_loss: 0.3227 - val_accuracy: 0.8526\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3163 - accuracy: 0.8561 - val_loss: 0.3231 - val_accuracy: 0.8513\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3182 - accuracy: 0.8540 - val_loss: 0.3213 - val_accuracy: 0.8523\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3202 - accuracy: 0.8514 - val_loss: 0.3198 - val_accuracy: 0.8522\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 0.4690 - accuracy: 0.8225 - val_loss: 0.3445 - val_accuracy: 0.8523\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3343 - accuracy: 0.8555 - val_loss: 0.3368 - val_accuracy: 0.8503\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3274 - accuracy: 0.8560 - val_loss: 0.3265 - val_accuracy: 0.8520\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3264 - accuracy: 0.8532 - val_loss: 0.3253 - val_accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3205 - accuracy: 0.8535 - val_loss: 0.3273 - val_accuracy: 0.8499\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8505 - val_loss: 0.3217 - val_accuracy: 0.8513\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3163 - accuracy: 0.8555 - val_loss: 0.3201 - val_accuracy: 0.85150s - loss: 0.3155 - accuracy: \n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3202 - accuracy: 0.8530 - val_loss: 0.3214 - val_accuracy: 0.8507\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3201 - accuracy: 0.8537 - val_loss: 0.3212 - val_accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3136 - accuracy: 0.8551 - val_loss: 0.3196 - val_accuracy: 0.8523\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4570 - accuracy: 0.8314 - val_loss: 0.3457 - val_accuracy: 0.8490\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3450 - accuracy: 0.8485 - val_loss: 0.3326 - val_accuracy: 0.8508\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.8545 - val_loss: 0.3278 - val_accuracy: 0.8515\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3275 - accuracy: 0.8480 - val_loss: 0.3228 - val_accuracy: 0.8508\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8510 - val_loss: 0.3217 - val_accuracy: 0.8521\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3169 - accuracy: 0.8548 - val_loss: 0.3218 - val_accuracy: 0.8515\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3204 - accuracy: 0.8508 - val_loss: 0.3214 - val_accuracy: 0.8522\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3168 - accuracy: 0.8525 - val_loss: 0.3208 - val_accuracy: 0.8509\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3165 - accuracy: 0.8529 - val_loss: 0.3206 - val_accuracy: 0.8507\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3151 - accuracy: 0.8544 - val_loss: 0.3237 - val_accuracy: 0.8498\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 5ms/step - loss: 0.4216 - accuracy: 0.8446 - val_loss: 0.3376 - val_accuracy: 0.8508\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3284 - accuracy: 0.8538 - val_loss: 0.3290 - val_accuracy: 0.8519\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3238 - accuracy: 0.8526 - val_loss: 0.3238 - val_accuracy: 0.8519\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3218 - accuracy: 0.8539 - val_loss: 0.3273 - val_accuracy: 0.8475\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3241 - accuracy: 0.8494 - val_loss: 0.3211 - val_accuracy: 0.8512\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3168 - accuracy: 0.8546 - val_loss: 0.3230 - val_accuracy: 0.8501\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3234 - accuracy: 0.8499 - val_loss: 0.3187 - val_accuracy: 0.8518\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3163 - accuracy: 0.8535 - val_loss: 0.3180 - val_accuracy: 0.8524\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3190 - accuracy: 0.8519 - val_loss: 0.3187 - val_accuracy: 0.8520\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3194 - accuracy: 0.8508 - val_loss: 0.3189 - val_accuracy: 0.8514\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.4119 - accuracy: 0.8354 - val_loss: 0.3373 - val_accuracy: 0.8471\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3276 - accuracy: 0.8526 - val_loss: 0.3243 - val_accuracy: 0.8490\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3195 - accuracy: 0.8551 - val_loss: 0.3258 - val_accuracy: 0.8493\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3198 - accuracy: 0.8538 - val_loss: 0.3209 - val_accuracy: 0.8518\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3179 - accuracy: 0.8529 - val_loss: 0.3227 - val_accuracy: 0.8503\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3197 - accuracy: 0.8518 - val_loss: 0.3241 - val_accuracy: 0.8482\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3197 - accuracy: 0.8524 - val_loss: 0.3193 - val_accuracy: 0.8519\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3181 - accuracy: 0.8519 - val_loss: 0.3181 - val_accuracy: 0.8524\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3151 - accuracy: 0.8541 - val_loss: 0.3187 - val_accuracy: 0.8517\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3141 - accuracy: 0.8555 - val_loss: 0.3196 - val_accuracy: 0.8507\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.4026 - accuracy: 0.8322 - val_loss: 0.3308 - val_accuracy: 0.8509\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.3274 - accuracy: 0.8522 - val_loss: 0.3229 - val_accuracy: 0.8518\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.3213 - accuracy: 0.8527 - val_loss: 0.3216 - val_accuracy: 0.8518\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.3211 - accuracy: 0.8530 - val_loss: 0.3208 - val_accuracy: 0.8519\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.3210 - accuracy: 0.8528 - val_loss: 0.3207 - val_accuracy: 0.8523\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.3182 - accuracy: 0.8537 - val_loss: 0.3179 - val_accuracy: 0.8520\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.3152 - accuracy: 0.8560 - val_loss: 0.3189 - val_accuracy: 0.8524\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.3162 - accuracy: 0.8520 - val_loss: 0.3207 - val_accuracy: 0.8506\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.3176 - accuracy: 0.8506 - val_loss: 0.3173 - val_accuracy: 0.8515\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.3152 - accuracy: 0.8532 - val_loss: 0.3244 - val_accuracy: 0.8512\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 5s 16ms/step - loss: 0.3957 - accuracy: 0.8439 - val_loss: 0.3299 - val_accuracy: 0.8509\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.3278 - accuracy: 0.8525 - val_loss: 0.3421 - val_accuracy: 0.8501\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.3215 - accuracy: 0.8528 - val_loss: 0.3230 - val_accuracy: 0.8489\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.3219 - accuracy: 0.8506 - val_loss: 0.3231 - val_accuracy: 0.8510\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.3180 - accuracy: 0.8528 - val_loss: 0.3219 - val_accuracy: 0.8518\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.3151 - accuracy: 0.8544 - val_loss: 0.3211 - val_accuracy: 0.8499\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.3177 - accuracy: 0.8524 - val_loss: 0.3192 - val_accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.3158 - accuracy: 0.8550 - val_loss: 0.3222 - val_accuracy: 0.8506\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.3122 - accuracy: 0.8572 - val_loss: 0.3198 - val_accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 0.3164 - accuracy: 0.8516 - val_loss: 0.3171 - val_accuracy: 0.8519\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3960 - accuracy: 0.8378 - val_loss: 0.3345 - val_accuracy: 0.8500\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.3282 - accuracy: 0.8515 - val_loss: 0.3228 - val_accuracy: 0.8525\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 0.3200 - accuracy: 0.8546 - val_loss: 0.3219 - val_accuracy: 0.8511\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3171 - accuracy: 0.8551 - val_loss: 0.3230 - val_accuracy: 0.8514\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3221 - accuracy: 0.8497 - val_loss: 0.3198 - val_accuracy: 0.8512\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3181 - accuracy: 0.8534 - val_loss: 0.3199 - val_accuracy: 0.8506\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3165 - accuracy: 0.8527 - val_loss: 0.3200 - val_accuracy: 0.8524\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3168 - accuracy: 0.8527 - val_loss: 0.3201 - val_accuracy: 0.8521\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3152 - accuracy: 0.8529 - val_loss: 0.3181 - val_accuracy: 0.8507\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 0.3146 - accuracy: 0.8565 - val_loss: 0.3184 - val_accuracy: 0.8514\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 6s 21ms/step - loss: 0.3991 - accuracy: 0.8425 - val_loss: 0.3330 - val_accuracy: 0.8495\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.3283 - accuracy: 0.8487 - val_loss: 0.3226 - val_accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.3176 - accuracy: 0.8551 - val_loss: 0.3217 - val_accuracy: 0.8505\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.3197 - accuracy: 0.8502 - val_loss: 0.3256 - val_accuracy: 0.8494\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 5s 20ms/step - loss: 0.3187 - accuracy: 0.8515 - val_loss: 0.3200 - val_accuracy: 0.8510\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.3181 - accuracy: 0.8535 - val_loss: 0.3194 - val_accuracy: 0.8520\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.3141 - accuracy: 0.8542 - val_loss: 0.3188 - val_accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.3157 - accuracy: 0.8552 - val_loss: 0.3191 - val_accuracy: 0.8521\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.3140 - accuracy: 0.8539 - val_loss: 0.3189 - val_accuracy: 0.8521\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.3133 - accuracy: 0.8556 - val_loss: 0.3199 - val_accuracy: 0.8511\n"
     ]
    }
   ],
   "source": [
    "parameters = [10, 20, 30, 50, 75, 100, 200, 300, 400, 500, 550, 600]\n",
    "losses2 = []\n",
    "val_losses2 = []\n",
    "for para in parameters:\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(para, activation=\"relu\", input_shape=(4,)), \n",
    "        keras.layers.Dense(para, activation=\"relu\"), \n",
    "        keras.layers.Dense(para, activation=\"relu\"), \n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")]\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]) \n",
    "    history2 = model.fit(X2, Y, batch_size=200, epochs=10, validation_split=0.5)\n",
    "    losses2.append(history2.history['loss'][-1])\n",
    "    val_losses2.append(history2.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error plot indicates that the training loss again stabilizes for $100$ neurons and more. However, the validation error is higher and more fluctant than in the case where we additionally took the past moves as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(parameters, losses2, label = \"Training Error\")\n",
    "plt.plot(parameters, val_losses2, label = \"Validation Error\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss Evolution (4 input variables)\")\n",
    "plt.xlabel(\"Amount of neurons in the first three layers\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Analysis with Leaky ReLU activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exactly the same analysis for the Leaky ReLU activation function to see if there are some differences to the \"simple\" ReLU activation. Note that we choose $\\alpha = 0.05$, which defines the slope of the Leaky ReLU function on the negative half-line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "alpha = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6830 - accuracy: 0.6030 - val_loss: 0.4249 - val_accuracy: 0.8403\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8451 - val_loss: 0.3726 - val_accuracy: 0.8489\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3629 - accuracy: 0.8489 - val_loss: 0.3527 - val_accuracy: 0.8523\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8515 - val_loss: 0.3420 - val_accuracy: 0.8550\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8544 - val_loss: 0.3323 - val_accuracy: 0.8576\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8573 - val_loss: 0.3287 - val_accuracy: 0.8575\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8581 - val_loss: 0.3231 - val_accuracy: 0.8585\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3229 - accuracy: 0.8594 - val_loss: 0.3213 - val_accuracy: 0.8594\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8608 - val_loss: 0.3196 - val_accuracy: 0.8604\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.8606 - val_loss: 0.3170 - val_accuracy: 0.8604\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.3957 - val_accuracy: 0.8464\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8513 - val_loss: 0.3399 - val_accuracy: 0.8547\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8567 - val_loss: 0.3276 - val_accuracy: 0.8579\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8576 - val_loss: 0.3228 - val_accuracy: 0.8590\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8620 - val_loss: 0.3182 - val_accuracy: 0.8593\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8614 - val_loss: 0.3161 - val_accuracy: 0.8597\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8606 - val_loss: 0.3146 - val_accuracy: 0.8612\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3083 - accuracy: 0.8623 - val_loss: 0.3119 - val_accuracy: 0.8609\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8663 - val_loss: 0.3116 - val_accuracy: 0.8615\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8645 - val_loss: 0.3102 - val_accuracy: 0.8618\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5243 - accuracy: 0.7646 - val_loss: 0.3521 - val_accuracy: 0.8504\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3424 - accuracy: 0.8539 - val_loss: 0.3312 - val_accuracy: 0.8545\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3259 - accuracy: 0.8554 - val_loss: 0.3209 - val_accuracy: 0.8596\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3193 - accuracy: 0.8589 - val_loss: 0.3138 - val_accuracy: 0.8619\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3134 - accuracy: 0.8591 - val_loss: 0.3107 - val_accuracy: 0.8621\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3058 - accuracy: 0.8631 - val_loss: 0.3109 - val_accuracy: 0.8610\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3031 - accuracy: 0.8646 - val_loss: 0.3070 - val_accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3047 - accuracy: 0.8617 - val_loss: 0.3106 - val_accuracy: 0.8612\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3055 - accuracy: 0.8622 - val_loss: 0.3057 - val_accuracy: 0.8633\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2997 - accuracy: 0.8662 - val_loss: 0.3048 - val_accuracy: 0.8641\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4848 - accuracy: 0.7921 - val_loss: 0.3306 - val_accuracy: 0.8579\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8582 - val_loss: 0.3166 - val_accuracy: 0.8596\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3097 - accuracy: 0.8619 - val_loss: 0.3114 - val_accuracy: 0.8590\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3074 - accuracy: 0.8623 - val_loss: 0.3085 - val_accuracy: 0.8604\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3033 - accuracy: 0.8651 - val_loss: 0.3058 - val_accuracy: 0.8627\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2983 - accuracy: 0.8655 - val_loss: 0.3061 - val_accuracy: 0.8630\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2986 - accuracy: 0.8667 - val_loss: 0.3047 - val_accuracy: 0.8611\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2979 - accuracy: 0.8654 - val_loss: 0.3052 - val_accuracy: 0.8612\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3013 - accuracy: 0.8634 - val_loss: 0.3029 - val_accuracy: 0.8643\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2977 - accuracy: 0.8654 - val_loss: 0.3009 - val_accuracy: 0.8644\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4473 - accuracy: 0.8264 - val_loss: 0.3314 - val_accuracy: 0.8564\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8585 - val_loss: 0.3219 - val_accuracy: 0.8565\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.8601 - val_loss: 0.3079 - val_accuracy: 0.8635\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3086 - accuracy: 0.8589 - val_loss: 0.3054 - val_accuracy: 0.8633\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3016 - accuracy: 0.8645 - val_loss: 0.3089 - val_accuracy: 0.8618\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3020 - accuracy: 0.8633 - val_loss: 0.3043 - val_accuracy: 0.8633\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2971 - accuracy: 0.8627 - val_loss: 0.3025 - val_accuracy: 0.8634\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2977 - accuracy: 0.8643 - val_loss: 0.3040 - val_accuracy: 0.8631\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2966 - accuracy: 0.8660 - val_loss: 0.3034 - val_accuracy: 0.8623\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2982 - accuracy: 0.8643 - val_loss: 0.3037 - val_accuracy: 0.8621\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4397 - accuracy: 0.8122 - val_loss: 0.3299 - val_accuracy: 0.8547\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3206 - accuracy: 0.8583 - val_loss: 0.3109 - val_accuracy: 0.8614\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3059 - accuracy: 0.8633 - val_loss: 0.3069 - val_accuracy: 0.8633\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3033 - accuracy: 0.8638 - val_loss: 0.3076 - val_accuracy: 0.8632\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2985 - accuracy: 0.8646 - val_loss: 0.3039 - val_accuracy: 0.8628\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2986 - accuracy: 0.8653 - val_loss: 0.3044 - val_accuracy: 0.8625\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2980 - accuracy: 0.8655 - val_loss: 0.3038 - val_accuracy: 0.8620\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2946 - accuracy: 0.8660 - val_loss: 0.3050 - val_accuracy: 0.8619\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2982 - accuracy: 0.8648 - val_loss: 0.2999 - val_accuracy: 0.8642\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2962 - accuracy: 0.8657 - val_loss: 0.3024 - val_accuracy: 0.8633\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 5ms/step - loss: 0.4147 - accuracy: 0.8333 - val_loss: 0.3200 - val_accuracy: 0.8608\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3103 - accuracy: 0.8635 - val_loss: 0.3071 - val_accuracy: 0.8624\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3035 - accuracy: 0.8637 - val_loss: 0.3042 - val_accuracy: 0.8623\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3004 - accuracy: 0.8639 - val_loss: 0.3031 - val_accuracy: 0.8634\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2987 - accuracy: 0.8638 - val_loss: 0.3023 - val_accuracy: 0.8627\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3023 - accuracy: 0.8617 - val_loss: 0.3013 - val_accuracy: 0.8633\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2988 - accuracy: 0.8649 - val_loss: 0.3003 - val_accuracy: 0.8627\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.2926 - accuracy: 0.8659 - val_loss: 0.3007 - val_accuracy: 0.8644\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.2965 - accuracy: 0.8631 - val_loss: 0.3014 - val_accuracy: 0.8620\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2947 - accuracy: 0.8623 - val_loss: 0.2990 - val_accuracy: 0.8632\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.4080 - accuracy: 0.8350 - val_loss: 0.3136 - val_accuracy: 0.8585\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3093 - accuracy: 0.8597 - val_loss: 0.3066 - val_accuracy: 0.8627\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3046 - accuracy: 0.8605 - val_loss: 0.3067 - val_accuracy: 0.8609\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3018 - accuracy: 0.8639 - val_loss: 0.3124 - val_accuracy: 0.8560\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3014 - accuracy: 0.8626 - val_loss: 0.3057 - val_accuracy: 0.8609\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.2979 - accuracy: 0.8646 - val_loss: 0.3009 - val_accuracy: 0.8641\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3003 - accuracy: 0.8636 - val_loss: 0.3023 - val_accuracy: 0.8619\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.2980 - accuracy: 0.8623 - val_loss: 0.2996 - val_accuracy: 0.8643\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.2945 - accuracy: 0.8644 - val_loss: 0.2989 - val_accuracy: 0.8623\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.2943 - accuracy: 0.8654 - val_loss: 0.3051 - val_accuracy: 0.8634\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 4s 13ms/step - loss: 0.3945 - accuracy: 0.8366 - val_loss: 0.3130 - val_accuracy: 0.8605\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.3130 - accuracy: 0.8596 - val_loss: 0.3070 - val_accuracy: 0.8626\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.3064 - accuracy: 0.8599 - val_loss: 0.3089 - val_accuracy: 0.8600\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.3039 - accuracy: 0.8630 - val_loss: 0.3011 - val_accuracy: 0.8631\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.2977 - accuracy: 0.8650 - val_loss: 0.3056 - val_accuracy: 0.8615\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.2980 - accuracy: 0.8636 - val_loss: 0.3022 - val_accuracy: 0.8618\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.2963 - accuracy: 0.8651 - val_loss: 0.3009 - val_accuracy: 0.8639\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.2971 - accuracy: 0.8654 - val_loss: 0.3011 - val_accuracy: 0.8632\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.2950 - accuracy: 0.8632 - val_loss: 0.2984 - val_accuracy: 0.8634\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.2935 - accuracy: 0.8662 - val_loss: 0.2985 - val_accuracy: 0.8636\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 0.3933 - accuracy: 0.8368 - val_loss: 0.3101 - val_accuracy: 0.8623\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3087 - accuracy: 0.8614 - val_loss: 0.3044 - val_accuracy: 0.8638\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3052 - accuracy: 0.8608 - val_loss: 0.3055 - val_accuracy: 0.8612\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3007 - accuracy: 0.8642 - val_loss: 0.3069 - val_accuracy: 0.8606\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 0.2958 - accuracy: 0.8657 - val_loss: 0.3045 - val_accuracy: 0.8606\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.2989 - accuracy: 0.8636 - val_loss: 0.3015 - val_accuracy: 0.8640\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.2940 - accuracy: 0.8647 - val_loss: 0.2992 - val_accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.2930 - accuracy: 0.8663 - val_loss: 0.3011 - val_accuracy: 0.8636\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.2948 - accuracy: 0.8665 - val_loss: 0.3006 - val_accuracy: 0.8606\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.2919 - accuracy: 0.8663 - val_loss: 0.3005 - val_accuracy: 0.8630\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3882 - accuracy: 0.8343 - val_loss: 0.3138 - val_accuracy: 0.8618\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.3110 - accuracy: 0.8586 - val_loss: 0.3102 - val_accuracy: 0.8604\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3028 - accuracy: 0.8609 - val_loss: 0.3069 - val_accuracy: 0.8607\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.3039 - accuracy: 0.8599 - val_loss: 0.3044 - val_accuracy: 0.8595\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.2999 - accuracy: 0.8640 - val_loss: 0.2999 - val_accuracy: 0.8627\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3005 - accuracy: 0.8640 - val_loss: 0.3030 - val_accuracy: 0.8626\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.2950 - accuracy: 0.8650 - val_loss: 0.2993 - val_accuracy: 0.8637\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.2962 - accuracy: 0.8629 - val_loss: 0.2987 - val_accuracy: 0.8638\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.2964 - accuracy: 0.8638 - val_loss: 0.3018 - val_accuracy: 0.8631\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.2934 - accuracy: 0.8663 - val_loss: 0.3103 - val_accuracy: 0.8608\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 7s 26ms/step - loss: 0.3849 - accuracy: 0.8396 - val_loss: 0.3209 - val_accuracy: 0.8553\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.3158 - accuracy: 0.8590 - val_loss: 0.3076 - val_accuracy: 0.8628\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 0.3105 - accuracy: 0.8574 - val_loss: 0.3042 - val_accuracy: 0.8623\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.2983 - accuracy: 0.8646 - val_loss: 0.3034 - val_accuracy: 0.8606\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 6s 22ms/step - loss: 0.2997 - accuracy: 0.8625 - val_loss: 0.3033 - val_accuracy: 0.8605\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.2996 - accuracy: 0.8633 - val_loss: 0.3010 - val_accuracy: 0.8635\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.2965 - accuracy: 0.8633 - val_loss: 0.3009 - val_accuracy: 0.8624\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.2946 - accuracy: 0.8653 - val_loss: 0.2993 - val_accuracy: 0.8635\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.2941 - accuracy: 0.8670 - val_loss: 0.2998 - val_accuracy: 0.8637\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.2964 - accuracy: 0.8636 - val_loss: 0.3036 - val_accuracy: 0.8605\n"
     ]
    }
   ],
   "source": [
    "parameters = [10, 20, 30, 50, 75, 100, 200, 300, 400, 500, 550, 600]\n",
    "losses3 = []\n",
    "val_losses3 = []\n",
    "for para in parameters:\n",
    "    model = keras.Sequential([\n",
    "     keras.layers.Dense(para, activation = LeakyReLU(alpha=alpha), input_shape=(9,)),\n",
    "     keras.layers.Dense(para, activation = LeakyReLU(alpha=alpha)),\n",
    "     keras.layers.Dense(para, activation = LeakyReLU(alpha=alpha)),\n",
    "     keras.layers.Dense(1, activation = \"sigmoid\")]\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]) \n",
    "    history3 = model.fit(X, Y, batch_size=200, epochs=10, validation_split=0.5)\n",
    "    losses3.append(history3.history['loss'][-1])\n",
    "    val_losses3.append(history3.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABLD0lEQVR4nO2dd5hU1fnHP+/2vvTekSpIFRRBUVFREXvBSjS2SIwm0V9MbNEYE2OMMbbYY8UWDSo2EATFAigWykpbpEmHXcouW97fH+fO7uyyZWZ3Zmdm9/08zzxz77nnnvueKfd7z3vOeY+oKoZhGIYRKHGRNsAwDMOILUw4DMMwjKAw4TAMwzCCwoTDMAzDCAoTDsMwDCMoTDgMwzCMoDDhMGIeEZktIj+vx/m7RaRHKG3yK/tuEbmujue+KyKXhNikiCMiY0QkJ8C8k0XkkxqO1+u798r4u4hcXZ8ymhomHE0QEckVkXERuO4zIrLfu1H7Xt80sA0H3GhUNUNVV4XhWq2Bi4F/+6X9XERWeHV/T0Q6VHe+qp6oqv8JtV1V2Hm7iDwf7uv4UNW5qtqnoa4XAPcCvxeRpEgbEiuYcBgNzT3ejdr3GhRpg8LIZGC6qu4DEJGxwJ+BU4EWwGrgpQjZFhFEJCHSNlRGVTcCy4CJkbYlVjDhMMoQkWQRuV9ENniv+0Uk2TvWSkTeFpGdIrJdROaKSJx37P9EZL2I5ItIjogcW4drvysiUyqlfSMiZ3jbo0Rkvojs8t5HVVNOhadnEekmIioiCSJyFzAGeNB74n/Qy6MicpC3nS0iz4rIFhFZIyI3+9Vzsoh8IiL3isgOEVktIifWUK0TgY/99icAr6rqYlXdD9wJHCkiPaupS1nrqLZre3nvFpEvRSRPRP4nIi28Y2NFZF2lsnNFZJyIjAd+D5xbXQvQ+35fq5T2TxF5wNv+mYgs9b7/VSJypV++sSKyzivjJ+DpyvaIyO9EZKV3/hIROf1AE+RB77tfVtPvS0Qu9WzZISLvi0hXXwEi8g8R2ex9Pt+JyAC/U2cDJ1dXrlEREw7Dnz8AhwGDgUHACOBm79hvgHVAa6At7majItIHmAIcqqqZwAlAbh2u/RIwybcjIv2BrsA73g3wHeABoCVwn5feMpgLqOofgLnAFK+1M6WKbP8CsoEewFE4V9PP/I6PBHKAVsA9wJMiItVccqCX1x+pYnsAgVHbtS8GLgXaA8W4z6tGVPU9XCvo5RpagFOBk0QkE0BE4oFzgBe945txopiF+6z+ISJD/c5vh2thdQWuqKL8lThBzwb+CDwvIu0r1XulV+/bgP/6RNEfETkV97s8A/c7nUt5i+544Eigt3edc4Btfqcvxf3mjQAw4TD8uQC4Q1U3q+oW3J/4Iu9YEe6G1FVVizw/tQIlQDLQX0QSVTVXVVfWcI3feq0W38vnw38DGOx7QvRs+a+qFuKeBJer6nOqWqyqL+FcC6eEsvLeDfE84CZVzVfVXODvlH8GAGtU9XFVLQH+g/tM2lZTZDMg32//PeAcETlERFKBWwEF0gI0sbZrP6eq36vqHuAW71rxAZZdLaq6BvgK8LUEjgH2qurn3vF3VHWlOj4GPsAJgY9S4DZVLfS57SqV/6qqblDVUlV9GViOe2jxsRm43/vdvYwTz6paB1cBd6vqUlUtxgmi7zdVBGQCfQHx8mz0Ozcf930ZAWDCYfjTAVjjt7/GSwP4G7AC+MBzR/wOQFVXANcBtwObRWSq1NDhC9yrqs38Xpd45eTjWhXnefkmAS9UY5fPto7BV7FGWgGJHPgZ+F/nJ9+Gqu71NjOqKW8H7mblyz8D98T8Oq5Vlou7Ya2r4tyqqO3aayvZnYirUyh4kfIW4fmUtzYQkRNF5HNxLsydwEmVrrtFVQuqK1hELhaRRb6HCVwLzP/89VoxGqv/79KfrsA//crZjmvVdVTVj4AHgYdwv9PHRCTL79xMYGe1tTcqYMJh+LMB9+fz0cVLw3sC/42q9sB1Iv7a52tW1RdVdbR3rgJ/reP1XwImicjhQAowqxq7fLatr6KMPVR8gm9X6XhN4aC34p5MK38GVV0nEL7FuUbKL676kKr2UtW2OAFJAL6vY/mV6ey33QVXl61U+ky8Vkhrf7MCKPtVYKyIdMK1PF70ykrG1eNeoK2qNgOmU9ElV235XmvgcZy7s6V3/veVzu9YySVX9rusxFrgykoPJqmqOg9AVR9Q1WFAf9z3coPfuf2ABh3hF8uYcDRdEkUkxe+VgLtx3ywirUWkFc6V8jyAiEwQkYO8P/AunIuqVET6iMgx3g2kANiHc03Uhem4m/YdOJ97qV96bxE5X1wn97m4P//bVZSxCNfh3EVEsoGbKh3fhOu/OADPBfQKcJeIZHo3tV/7PoM61uco3473OQ/wOmq7AI8B/1TVHXUsvzIXikh/EUnDfYaveXX6AUgRkZNFJBHXb5Xsd94moJt4gwCqwnNdzgaeBlar6lLvUJJX1hagWFyH/fFB2JyOE5Yt4DraObDPpw1wrYgkisjZuJv89CrKehS4SUQO9srK9vIjIoeKyEiv/ntwv1X/3+lRwLtB2N2kMeFoukzH3eR9r9uBPwELcE/K3+H82n/y8vcCZgC7gc+Ah1V1Fu6m8Rfck+1PuD955Zu1PzdKxXkcW30HvP6M/wLj8HOFqOo2XOfrb3AdmjcCE1R1K5VQ1Q+Bl706LORAcfkncJY36qaqzuNf4m4sq4BPPDueqqE+NfEsrlM51dtP8crbDXyJ+xxvqWPZVfEc8Azue0gBrgVQ1V3AL4AncK2nPVR0j73qvW8Tka9qKP9FDvxu8r3rvIJzzZ0PTAvUYFVdgutH+gwnYAOBTytl+wL3+9sK3AWc5f0mKpf1Bq61O1VE8nAtF9/Isyxcy2YHztW1Ded+xeuI7w+8GajdTR2xhZwMI3yIyJ+Bzap6f5ivMxt4XlWfCOd1GiMi8ndgpao+HGlbYoWom4xjGI0JVf19pG0wakZVfxNpG2INc1UZhmEYQWGuKsMwDCMorMVhGIZhBEWT6ONo1aqVduvWLdJmGIZhxBQLFy7cqqqtK6c3CeHo1q0bCxYsiLQZhmEYMYWIVI7YAJiryjAMwwgSEw7DMAwjKEw4DMMwjKBoEn0chmGEl6KiItatW0dBQbVBcI0oJiUlhU6dOpGYmBhQfhMOwzDqzbp168jMzKRbt25Uv66VEY2oKtu2bWPdunV07949oHPMVWUYRr0pKCigZcuWJhoxiIjQsmXLoFqLJhyGYYQEE43YJdjvzoSjJr55GeY/GWkrDMMwogoTjppY8iYsqOtSDIZhNBTbtm1j8ODBDB48mHbt2tGxY8ey/f3799d47oIFC7j22mtrvcaoUaNCYuvs2bPJzs4us2/w4MHMmDEjJGU3FNY5XhPprWGdzTg3jGinZcuWLFq0CIDbb7+djIwMfvvb35YdLy4uJiGh6tvd8OHDGT58eK3XmDdvXkhsBRgzZgxvv13VApYOVUVViYuLq3K/OmqqZyixFkdNZLSBvVuhtCTSlhiGESSTJ0/mqquuYuTIkdx44418+eWXHH744QwZMoRRo0aRk5MDuBbAhAkTACc6l156KWPHjqVHjx488ED5IpEZGRll+ceOHctZZ51F3759ueCCC/BFGZ8+fTp9+/Zl2LBhXHvttWXlBkJubi59+vTh4osvZsCAAcydO7fC/tq1a7nhhhsYMGAAAwcO5OWXXy6zZ8yYMUycOJH+/fuH5LOrDWtx1ER6a9BS2LcD0ltF2hrDiAn++NZilmzIC2mZ/TtkcdspBwd93rp165g3bx7x8fHk5eUxd+5cEhISmDFjBr///e95/fXXDzhn2bJlzJo1i/z8fPr06cPVV199wPyGr7/+msWLF9OhQweOOOIIPv30U4YPH86VV17JnDlz6N69O5MmTarWrrlz5zJ48OCy/ddff534+HiWL1/Of/7zHw477DByc3Mr7L/++ussWrSIb775hq1bt3LooYdy5JFHAvDVV1/x/fffBzyctr6YcNREuhcUcvdmEw7DiEHOPvts4uPjAdi1axeXXHIJy5cvR0QoKiqq8pyTTz6Z5ORkkpOTadOmDZs2baJTp04V8owYMaIsbfDgweTm5pKRkUGPHj3Kbt6TJk3iscceq/IaVbmqcnNz6dq1K4cddlhZmv/+J598wqRJk4iPj6dt27YcddRRzJ8/n6ysLEaMGNFgogEmHDWT0ca979mMW8veMIzaqEvLIFykp6eXbd9yyy0cffTRvPHGG+Tm5jJ27Ngqz0lOTi7bjo+Pp7i4uE556mtvVfuBnhdurI+jBm764Ce3sWdrZA0xDKPe7Nq1i44dOwLwzDPPhLz8Pn36sGrVKnJzcwHK+iBCxZgxY3j55ZcpKSlhy5YtzJkzhxEjRoT0GoFiwlEDxSmee2r35sgaYhhGvbnxxhu56aabGDJkSMhaCP6kpqby8MMPM378eIYNG0ZmZibZ2dlV5vX1cfher732Wq3ln3766RxyyCEMGjSIY445hnvuuYd27dqFuhoB0STWHB8+fLjWZSGnm17/hju+O4bE0b+EcbeH3jDDaCQsXbqUfv36RdqMiLN7924yMjJQVa655hp69erF9ddfH2mzAqKq71BEFqrqAWOVrcVRA1mpSWzTLNizJdKmGIYRAzz++OMMHjyYgw8+mF27dnHllVdG2qSwYJ3jNZCVmshWzaJ1/mbiI22MYRhRz/XXXx8zLYz6YC2OGshKSWCrZlOab30chmEYPkw4aiArNZGtZJuryjAMww8TjhrISnGuqvh9W6AJDCIwDMMIhLAKh4iMF5EcEVkhIr+r4vhVIvKdiCwSkU9EpL+X3lJEZonIbhF5sNI5s70yF3mvNuGyPyvVuariSvZDYWhDKBiGYcQqYRMOEYkHHgJOxE27nuQTBj9eVNWBqjoYuAe4z0svAG4BfkvVXKCqg71X2DogXIvDG4e929xVhhGtHH300bz//vsV0u6//36uvvrqas8ZO3YsvmH6J510Ejt37jwgz+233869995b47XffPNNlixZUrZ/6623hiRMejSHXw9ni2MEsEJVV6nqfmAqcKp/BlX1f4xPB9RL36Oqn+AEJGJkpSayjSy3Y/0chhG1TJo0ialTp1ZImzp1ao2BBv2ZPn06zZo1q9O1KwvHHXfcwbhx4+pUVmXGjBnDokWLyl6Vy1VVSktLq92vjvpOgAyncHQE1vrtr/PSKiAi14jISlyLo/bVVBxPe26qWySM61VWaHHssZFVhhGtnHXWWbzzzjtlizbl5uayYcMGxowZw9VXX83w4cM5+OCDue2226o8v1u3bmzd6kIL3XXXXfTu3ZvRo0eXhV4HN0fj0EMPZdCgQZx55pns3buXefPmMW3aNG644QYGDx7MypUrmTx5ctlM8JkzZzJkyBAGDhzIpZdeSmFhYdn1brvtNoYOHcrAgQNZtmxZwHWNhvDrEZ/HoaoPAQ+JyPnAzcAltZxygaquF5FM4HXgIuDZyplE5ArgCoAuXbrUybaUxDh2xjVzOxZ2xDAC493fwU/fhbbMdgPhxL9Ue7hFixaMGDGCd999l1NPPZWpU6dyzjnnICLcddddtGjRgpKSEo499li+/fZbDjnkkCrLWbhwIVOnTmXRokUUFxczdOhQhg0bBsAZZ5zB5ZdfDsDNN9/Mk08+yS9/+UsmTpzIhAkTOOussyqUVVBQwOTJk5k5cya9e/fm4osv5pFHHuG6664DoFWrVnz11Vc8/PDD3HvvvTzxxBMH2BOt4dfD2eJYD3T22+/kpVXHVOC02gpV1fXeez7wIs4lVlW+x1R1uKoOb926daA2V0BEKE5uQSligQ4NI8rxd1f5u6leeeUVhg4dypAhQ1i8eHEFt1Jl5s6dy+mnn05aWhpZWVlMnDix7Nj333/PmDFjGDhwIC+88AKLFy+u0Z6cnBy6d+9O7969AbjkkkuYM2dO2fEzzjgDgGHDhpUFRqxMZVdVz549AeoUfh0IWfj1cLY45gO9RKQ7TjDOA873zyAivVR1ubd7MrCcGhCRBKCZqm4VkURgAhDW3qL01GT2FGSRaa4qwwiMGloG4eTUU0/l+uuv56uvvmLv3r0MGzaM1atXc++99zJ//nyaN2/O5MmTKSioW9fp5MmTefPNNxk0aBDPPPMMs2fPrpe9vtDsdQnLHunw62FrcahqMTAFeB9YCryiqotF5A4R8cn4FBFZLCKLgF/j56YSkVzcKKvJIrLOG5GVDLwvIt8Ci3CC9Hi46gCug3xXXHNzVRlGlJORkcHRRx/NpZdeWtbayMvLIz09nezsbDZt2sS7775bYxlHHnkkb775Jvv27SM/P5+33nqr7Fh+fj7t27enqKiIF154oSw9MzOT/Pz8A8rq06cPubm5rFixAoDnnnuOo446KhRVrZGGCL8e1j4OVZ0OTK+Udqvf9q9qOLdbNYeGhcS4AMlKSWT7rmw6mavKMKKeSZMmcfrpp5e5rAYNGsSQIUPo27cvnTt35ogjjqjx/KFDh3LuuecyaNAg2rRpw6GHHlp27M4772TkyJG0bt2akSNHlonFeeedx+WXX84DDzxQITx6SkoKTz/9NGeffTbFxcUceuihXHXVVUHVp3Ifx80338zw4QcEq63A6aefzmeffcagQYMQkbLw68F0wNeGhVWvhV+8sJCzVt/GMVnr4dqvQ2yZYTQOLKx67GNh1UNIVkoim0qzbAKgYRiGhwlHLWSlJrKhKBP250PRvkibYxiGEXFMOGohKyWBTaWZbsdmjxtGtTQFt3djJdjvzoSjFtxiThavyjBqIiUlhW3btpl4xCCqyrZt20hJSQn4nIjPHI92LOyIYdROp06dWLduHVu22MNVLJKSkkKnTp0Czm/CUQtZqQlu3XEwV5VhVENiYmJIZiQbsYG5qmohK8VbBRBsEqBhGAYmHLWSlZpIIUkUJWRYi8MwDAMTjlrJSkkEYF9SCxMOwzAMTDhqJSvVdQPtSWhhrirDMAxMOGolNTGehDghL6GZtTgMwzAw4agVESErNZGd0syEwzAMAxOOgMhKSWAb2bB3O5TUb61ewzCMWMeEIwCyUhPZUpoNKOy18OqGYTRtTDgCICslkZ9KLF6VYRgGmHAERFZqAhuKMtyOjawyDKOJY8IRAFkpiaz1CYe1OAzDaOKYcARAVmoiuQXeIu/W4jAMo4ljwhEAWSkJbC9ORuOTrcVhGEaTx4QjALJSEwGhNK21CYdhGE0eE44A8MWrKkptZa4qwzCaPCYcAeCLV1WYbIEODcMwTDgCwNfi2JtowmEYhmHCEQCujwN2J3jCUVoaYYsMwzAihwlHAPhaHHlxzaC0GAp2RtQewzCMSGLCEQC+Po4dcc1cgrmrDMNowphwBIBvTY6tamuPG4ZhmHAEgG9Njs2lFujQMAzDhCNAslIS+Kk4y+2YcBiG0YRJiLQBsUJWaiIbixJA4s1VZRhGk8ZaHAGSlZLIroISSG8Fe0w4DMNouphwBEhWagJ5BcWQ3hr22CqAhmE0XUw4AiQrJZG8fUVOOMxVZRhGXSkqgLd/DdtXR9qSOhNW4RCR8SKSIyIrROR3VRy/SkS+E5FFIvKJiPT30luKyCwR2S0iD1Y6Z5h3zgoReUBEJJx18JGVmkheQRFktDFXlWEYdWfFDFjwJMy+O9KW1JmwCYeIxAMPAScC/YFJPmHw40VVHaiqg4F7gPu89ALgFuC3VRT9CHA50Mt7jQ+99QeSlZJAQVEpxWlehFzVhrisYRiNjZzp7v3712HX+sjaUkfC2eIYAaxQ1VWquh+YCpzqn0FV8/x20wH10veo6ic4ASlDRNoDWar6uaoq8CxwWviqUI4vXlVBajsoLoB9OxrisoZhNCZKiiHnXeg62j18fvFopC2qE+EUjo7AWr/9dV5aBUTkGhFZiWtxXBtAmetqK9Mr9woRWSAiC7Zsqf+8C1+8qj3JbV3CrnU15DYMw6iCtV/Avu0w4udw8Gmw8BkoyKvtrKgj4p3jqvqQqvYE/g+4OYTlPqaqw1V1eOvWretdni9e1a4kTzjyYrOJaRhGBMmZDvFJcNA4OHwKFObBV89G2qqgCadwrAc6++138tKqYyq1u53We+UEWmbI8LU4tsd7ImQtDsMwgkEVlr0D3Y+E5EzoONS5rL54FEqKIm1dUIRTOOYDvUSku4gkAecB0/wziEgvv92TgeU1FaiqG4E8ETnMG011MfC/0JpdNb4+jq1kQ1yitTgMwwiOLctgx2roc1J52qgpsGstLGmQ21jICFvIEVUtFpEpwPtAPPCUqi4WkTuABao6DZgiIuOAImAHcInvfBHJBbKAJBE5DTheVZcAvwCeAVKBd71X2Clbk6OgFLLax+xoCMMwIsSyd9y7v3D0OgFa9oJ5D8CAM6FhZhfUm7DGqlLV6cD0Smm3+m3/qoZzu1WTvgAYECITA8bXx5FXUARZnazFYRhGcORMh47D3IOnj7g41+p461eQ+wl0HxM5+4Ig4p3jsYJvTY68fUWQ3dH6OAzDCJy8jbB+YcXWho9DzoO0VjDvXw1vVx0x4QgQ35ocrsXREfI22NrjhmEExg+eR73vyQceS0yBEVfA8vdhS07D2lVHTDiCICslgbx9xZDdCUqLbF0OwzACY9k70Lw7tO5b9fFDL4OEFPjswaqPRxkmHEFQocUBkGfuKsMwaqEwH1bPca2N6jq/01vB4PPhm5djIoiqCUcQlEXIzfaEw0ZWGYZRGytmQMn+qvs3/DnsGpfvy8cbxq56YMIRBGVrcmR5cxBtZJVhGLWxbDqktoDOI2vO1+ogJy7zn4D9exvGtjpiwhEEZS2OtBbOH2kjqwzDqImSItfp3Xs8xAcw+2HUL10sq29eDL9t9cCEIwjK+jhEvJFV1uIwDKMG1syDgl1Vj6aqii6Hubkenz0EpSXhta0emHAEgW9NjsLiEpvLYRhG7eRMd96JnkcHll/EtTq2r3Lh16MUE44g8MWryvf1c1jnuGEY1eELatjjaEhKD/y8vqdAsy5RPSHQhCMIyuJV+UZW7f7JLcxiGIZRmZ++cwEM+9Yymqoy8QluhNXaz2Ht/PDYVk9MOIKgPF5Vsevj0FLI3xhhqwzDiEpypgPiOsaDZciFkJINn0Vnq8OEIwgqtjhsSK5hGDWw7B3oPAIy2gR/bnIGDL8Ulr4F21eH3rZ6YsIRBL4+jrwCP+GwDnLDMCqzcy389G3tk/5qYsSVIPHw+SOhsytEmHAEQXmLo9gv7Ii1OAzDqIRvRFTfCXUvI6s9DDwbvn4O9m4PjV0hwoQjCCqsyZGSBclZNrLKMIwDyXkHWvV2s8Hrw6gpULQXFj4dGrtChAlHEFRYkwNsEqBhGAeyb6dblKk+biofbQ+GnsfAF/+G4sL6lxciTDiCoMKaHGCTAA3DOJDlH0JpceCzxWtj1C9h9yb47tXQlBcCTDiCpGxNDrAWh2EYB5LzDqS3gY7DQ1Nej6Oh7QCY96CbVBgFmHAEScUWRye3mFMUNSENw4ggxYWwfAb0Ge/WEw8FInD4FNiyFFbMDE2Z9SSgmonI2SKS6W3fLCL/FZGh4TUtOimLkAs2ssowjIrkzoX9+dAnRG4qHwPOhMz2UTMhMFBJvEVV80VkNDAOeBKIvsHFDUDZmhxgCzoZhlGRZdMhMR16HBXachOSYOSVsGo2bPw2tGXXgUCFwxff92TgMVV9B0gKj0nRTcUWh80eNwzDo7TUzd846BhITA19+cN+BkkZUbEueaDCsV5E/g2cC0wXkeQgzm1UZKclsnNvEaWlClkdXKKNrDIMY+PXkL8h9G4qH6nNYOjF8P3rEfdyBHrzPwd4HzhBVXcCLYAbwmVUNNOpWSr7S0rZsrsQktLckpDW4jAMY9l0FyKk9wnhu8bIq1xw1S8eDd81AiAg4VDVvcBmYLSXVAwsD5dR0Uyn5mkArNvhrQmc3THi6m8YRhSQMx26HO6Wlg4XzbtC/9Ng4TNQkBe+69RCoKOqbgP+D7jJS0oEng+XUdFM5xbOd7luxz6XkNXJWhyG0dTZvho2Lwl+7Y26MGoKFOa5GFYRIlBX1enARGAPgKpuADLDZVQ007GZa3Gs3e7f4rA+DsNo0uRMd++hCDNSGx2HQdcjXNTcCC0kF6hw7FdVBRRARIJYB7FxkZoUT6uMJL8WR0co2An790TULsMwIsiy6dDmYGjRvWGud/gUt7rgkjcb5nqVCFQ4XvFGVTUTkcuBGcDj4TMruunUPK1cOMrW5TB3lWE0SfZuhx/nNYybykfv8dDyILcueQTCkATaOX4v8BrwOtAHuFVVo2MKYwTo1DyVtb7O8bLZ4+auMowmyQ/vu5FODeGm8hEX51odGxfBmk8b7rq+yweSyXNNfaSqN+BaGqkikhhWy6KYTs3T2LBzHyWlarPHDaOps+xtyOwAHYY07HUHnQdprVyro4EJ1FU1B0gWkY7Ae8BFwDPhMira6dwilaISZXN+gfvBIDayyjCaIkX7YOVH0OdEF4ywIUlMhRGXww/vwZYfGvTSgQqHeHM5zgAeUdWzgYNrPUlkvIjkiMgKEfldFcevEpHvRGSRiHwiIv39jt3knZcjIif4pef6nbMgQPtDim8ux9rt+1wMmYw2NrLKMJoiqz52K/Q1ZP+GP4f+HBJSGjwMScDCISKHAxcA73hp8bWcEA88BJwI9Acm+QuDx4uqOlBVBwP3APd55/YHzsOJ03jgYa88H0er6mBVDVHA++Do1Nw3l8Ovn8NaHEag/PQdFO+PtBVGKMh5B5IyoduYyFw/vRUMmgTfTIXdmxvssoEKx3W4yX9vqOpiEekBzKrlnBHAClVdpar7ganAqf4ZVNV/6mM63nBfL99UVS1U1dXACq+8qKBjs0qTAG32uBEoc++DR0fDKxdDSVGkrTHqQ2kp5LwHvY6DhOTI2XH4NVCyH+Y/0WCXDHRU1ceqOlFV/yoiccBWVb22ltM6Amv99td5aRUQkWtEZCWuxXFtAOcq8IGILBSRK6q7uIhcISILRGTBli1bajE1OFIS42mTmVw+CdA3ezxKVucyopS5f4eZf3SdqD+8C/+7xt18jNhk/QLYszl0S8TWlVa9XB/Ll4/D/r0NcslAR1W9KCJZ3uiq74ElIhKSIIeq+pCq9sSFNLk5gFNGq+pQnAvsGhE5sppyH1PV4ao6vHXr1qEwtQKdmqdWbHHs3+0mAhpGVcz9O8y8AwaeDZfNgGNuhm9fhvd+Zw8cscqydyAuAQ4aF2lL3Lrk+7bDNy81yOUCdVX199xKpwHvAt1xI6tqYj3Q2W+/k5dWHVO98ms8V1V975uBN4iQC6tzi7TyuRztDnHvuQ0/ntqIAfxF47RHIT4BxvzWjcP/8t8w+y+RttCoC8vegW6jXbjzSNPlcOgwFD57CEpLas9fTwIVjkRv3sZpwDRVLaK8P6I65gO9RKS7iCThOrun+WcQkV5+uydTHnF3GnCeiCSLSHegF/CliKT7LWGbDhyPawE1OJ2ap7JxVwHFJaXQdRSkNHPjuQ3Dnzn3lovG6f92ogFu6Obxf4LBF8LHf3Fxh4zYYety2LY8fGtvBIuIa3VsX+kWkwozCQHm+zeQC3wDzBGRrkCNMX1VtVhEpuDW8YgHnvI61u8AFqjqNGCKiIwDioAdwCXeuYtF5BVgCS6E+zWqWiIibYE3xI2XTsCNynovqBqHiM7N0ygpVX7KK3DDc3uPd19YSXH5zcFo2sy5Fz66EwaeA6c/CnGVBiKKwCn/dC7O937nHj4GT4qEpUawLPMGl/Y5MbJ2+NNvImR3cUNz+00I66UCusOp6gPAA35Ja0Tk6ADOmw5Mr5R2q9/2r2o49y7grkppq4BBgdgcbvzncnRqnuY6yL6d6mLWdK+y28VoSsz5G3z0p+pFw0d8Apz5JLx4jussT8mO3JwAI3BypjsXdbPOtedtKOIT4PBfuIeQdQugU/hmKwTaOZ4tIvf5RimJyN9xw2ebLAfM5TjoWDcRx/ckYjRdfKJxyLk1i4aPxBQ47wVoPwhenQyr5zaImUYd2b0Z1n4JfcP7VF8nhlzoHj7CHIYk0D6Op4B83BKy5+DcVE+Hy6hYoEOzVET85nIkpUPPY5xw2CiZpsvHfqJx2iO1i4aP5Ey48HUXlvulSbD+q/DaadSdH94DNDpbhsmZMOxnsHQa7MgN22UCFY6eqnqbN5lvlar+EegRNqtigKSEONplpZSPrALnrtq1FjZ+EznDjMjx8d9g1p/gkPOCEw0faS3gojcgtTk8fyZsyQmPnUb9WDbd9SW0HRBpS6pm5JVu7fMwDrgIVDj2iYhvvXFE5AhgX3hMih0qzOUA10Euceauaop8fI+faDwcvGj4yOoAF7/p5gc8dzrs/DGkZhr1ZP8eWDXLtTYaOqhhoGR1gIFnwVfPubVCwkCgwnEV8JAXYDAXeBC4MiwWxRCdm6ex3l840lu58dShFI6SYheHZs+20JVphJaP74FZd7mYQfURDR8te8JF/4XC3fDsabA7tJEPjHqw8iMoLmjYtTfqwuFToGgPLAxPj0KgIUe+UdVBwCHAIao6BDgmLBbFEG4uxz6KSvzCRvSdAJsXw/ZVobnIV8/AG1fC40fDpiWhKdMIHbP/Wi4apz5Uf9Hw0W4gXPAK5G2A50+Hgl2hKdeoH8umu87nrqMibUnNtBvg+ly/eAyKC0NefKAtDsAFJfQLTPjrkFsTY3RqnkapwsadBeWJvg6zULQ6CvPdrOJ2A92X/+Rx7odrRAez/wqz/wyDzg+taPjochic+zxsXgYvntdgcYiMaigpdh3jvU6A+BhYx+7wKS74YRj6yoISjkpEqYOv4ejUotKQXIDm3aDtwNAIx7wHYc8WmPBPuGKWC2Y29XwXYdVGbkWW2X/xE40HQy8aPnqNgzP+DT9+5obqWkTdyLH2CxcPKtJBDQOl5zFw/WJof0jIi66PcDT5O1dn3yTAHZWeBPueDD9+Xj/fdP5Pbiz2wadDp2Guw+tn78KAM1yE1f9eAUUFtZdjhJ7Zf4HZd8PgC8IrGj4GnAkT7oPl78ObV1tE3UiRMx3ik9ycrVhABJLSwlJ0jcIhIvkiklfFKx/oEBaLYoh22SnE+c/l8NH3ZEBd6Oy6Mvsvrpl57K3laYmpbpbxMTfDd6/AMyc5gTEajll3l4vGxH+FXzR8DL/U/Ra+exXevdFanA2NqvMidD/KzZVo4tQoHKqaqapZVbwyVbXJB2RKjI+jfXbqgcLRbiA06wJL6xj0cMsP8NWz7mbRotJ0GRE48oZy3/djR9tksYZi1t0uIOHgCxtWNHyM/rULZDf/cZj154a9dlNn81LYsTo6J/1FgPq4qgzcyKqyBZ18iLjRVatmuw7uYJn5R0hMg6NurD5Pv1Pgsg/ceP+nT4TvXw/+OkbgRFo0wP2ujrsThlwEc+5xIbSNhiHH67PsHUVBDSOICUc96dQ87cAWBzh3VUkhrJgZXIFrPnPh2Udf5+aF1ES7AXD5R25FudcudaEuzP8deg4QjQj+bXwRdftNhPd/D1+/EDlbmhLLpkPHYZDVPtKWRAUmHPWkc4tUNuUXUFhcafGUzodBaovgRlepwoe3QGZ7OOwXgZ2T0RounuY9hf4NXrnITRwz6o+qcwlFi2j4iIuHM5+AHmNh2pS6u0SNwMjbCBu+iv5Jfw1IFPwLYptOzdNQhQ07K41wik9wsfp/eD/wIZRL34J18+Ho3wc3GiIhyd3Uxv/Fjfx46gTYsSbw840DUXWd4B//1UUcjRbR8JGQDOe+4FZ9e+1nsOrjSFvUeMnx5k5FYzTcCBFF/4TYpHPl8Or+9J0AhbsgN4Aw2SVFMON2aN3PzQ0IFhE47Gq44FXYudbNNF/0ormu6kJZS8MTjVOiTDR8JGe477vlQW5+z/qFkbaocZIz3Q1Sad0n0pZEDVH4b4gtOrVwLYMq+zl6Hu06uQNxVy18xi37eNwf67eC4EHj4PKZbiLim1fD42Mh95O6l9fU8InGnHuc+y9aRcNHWgu48L+Q1hKeP8uNtDNCR2E+rJ7j3FTRGtQwAkTxPyI2aJeVQkKcHDiyCty8i57HuI61mp78faFFuo6GXsfX36hWveCyGXDGEy444jMnw9QLYNvK+pfdmFF1cafKROOB6BYNH1ntXUTd+EQXUdfclKFjxQw3nypWZos3EDHwr4hu4uOEDs2qmMvho+8EyN8AG7+uvpB5/4K9W+G4O0L3VBMXB4ecDb9cAMfc4oYGPzQS3vs97NsRmms0JspE428w9OLYEQ0fLXq4tTyK9sBzp7lV6oz6s+wd15rrPDLSlkQVMfTPiF7cuhzVBKDrfYJbVKW6kS9loUXOcKFFQk1iKhz5W/jlVzD4fPjiEXhgCHz+qMU98qHqhjL7RGPCP2NLNHy0PRjOf9X9pp47A/btjLRFsU1JESz/wK2zE4l5O1FMDP47oo9OzVNZW12LI60FdDui+n6O2Xe7H+ixt4TPQIDMtjDxAbhyrlvb+r3/g4cPc260phy+wicac++NbdHw0WUknPscbFkGL55rEXXrw5pPXTh7G4Z7ADH8D4keOjdPY0t+IQVFJVVn6DsBtubA1uUV07fkuNAih152YGiRcNFuAFz0pnsylTiYOgn+cwps/LZhrh9NqMJHd3qicUnsi4aPg8bBmY+7aK6vXAzF+yNtUWyybDokeP2URgUawb8k8vRqmwHAt+uqWWzH98RSudUx44+QlOFiTzUkItD7eLh6Hpx0L2xaDP8+Ev53jZvs1BQoE42/e6Jxf+MQDR8Hnw6n3A8rPoQ3r4LSah5qjKpRdcNwex4dtgizsUwj+qdEjiMOakVivDBz6aaqMzTr7NxD/sKxZp6LfxNIaJFwEZ8IIy6Ha792wfO+fQX+NcwthdqYXRyqMPMOJxrDJjc+0fAxbDKM+6OLYzb9hqbtkgyWn76DXWvNTVUNjfDf0vBkpiRyWI+WfFidcIBzV6370nVcqsIHt0BmBxh5dcMZWh2pzeD4O+GaL9zCQbPucgLyzdTGN4HQJxqf3OdurCf/o3GKho/R18ER18GCJ11fjhEYOdMBcR3jxgE04n9MwzKuX1tWbdnDqi3VxInyhSvImQ5L/gfrFwQfWiTctOgB5zwLP3sPMtuVr3We+2mkLQsNqi7y8Cf3wbCfNX7R8DHudueOm3uvG8Fn1M6yt90Q3IzWkbYkKmkC/5qG4dh+bQCYubSa8fNt+kHz7rD4DXfzat3PDY+NRroeDj+fCWc87paufeYkePnC2J5AWCYa//BE476mIRrg+rQm/AP6nwYf3AxfPRdpi6KbnT86V5WtvVEtTeSfE346NU+jX/us6t1VIm726eo5sH2Vm+wXzWPD4+LgkHNgygK34uCKj9wEwvf/EHsTCFVdHLBP/uEWx2pKouEjLt49CPQ8Bt66FpZMi7RF0UuOt3JnH5stXh1N7N8TXsb1a8OC3O3s2FPN8Eefu6rbGOh1XMMZVh+S0tyor2u/hsGT3OJBDwyBL/4dGxMIfaLx6f1ONE76e9MTDR8JSW7lyI7D4fXLXDQB40CWvQOt+kCrgyJtSdTSRP9B4WFcv7aUKsz+oRp3VeeRcOSNbhRPrAVMy2zrQotfNRfaHeLWvX74MPd0Fq2jdVRhxm2eaFzWtEXDR1I6XPAKtOwFL50P6xZE2qLoYt9ON/HP3FQ10sT/RaFlYMds2mQmM2NJNcIRFwfH/CG2n2TaDYSL/wfnvwIIvHQePDsx+iYQlonGPz3RuNdEw0dqc7jov67j94Wz3HrahmP5h1BabG6qWrB/UgiJixOO7deWj3/YcuCKgI0JEReD6xefwYl/g5++L59AmP9TpK3zVlK8tVw0TraWxgFktnMRBOKTvYi6uZG2KPKowtJpkNHWLRNrVIv9m0LMuH5t2F1YzBertkfalPATnwgjr4Brv4LDr4FvXoYHhsLHf4vcBEKfaMx7oFw0Ys0t2FC06O5F1N0Hz54G+TXMQ2qslJbAms9c1Oj7D3HC0f9Ue9CohbB+OiIyXkRyRGSFiPyuiuNXich3IrJIRD4Rkf5+x27yzssRkRMCLTPSHHFQK1IS45hR02TAxkZqczjhLpjyJRx0LMz6Ezw43AlJQ04g9K3ZPu8BOPTnJhqB0LY/XPCaC8P+/BmxN2KuLhTvd+tsvPUr+HsfeHo8zH/cfRanPgTH3RlpC6Me0TB1bIpIPPADcBywDpgPTFLVJX55slQ1z9ueCPxCVcd7AvISMALoAMwAenun1VhmVQwfPlwXLGi4TsDLn13Akg15fPJ/RyNN8ca1Zh68/3vY8DV0GAIn/Bm6jgrvNctE419ONE6610QjGFbOghfPcd/XRW+4TvTGxP49sGImLH0LfnjfLemclOEWTus3wb0nZ0bayqhDRBaq6vDK6fVYo7RWRgArVHWVZ8BU4FSg7CbvEw2PdMCnYqcCU1W1EFgtIiu88qitzGjguH5t+XDJJpZuzKd/h6xIm9PwdB0FP/8IvnvVTbp7+kToN9EtixuOKMCqbmLbZw/CoZfDSX8z0QiWnkfDmU/Cq5e4iLrnveSG78Yy+3Y4kVj6lhON4n2Q2gL6neJePcZCYkqkrYxJwikcHYG1fvvrgAOW0RKRa4BfA0mAL35xR+DzSud29LZrLdMr9wrgCoAuXboEb309OLpvG0RgxtJNTVM4wPmIB53r/qCfPeQm3+W8CyOvdPNCUpuF5jomGqGj/0S38uG0KS7czJlPRPck1arI3+SChy59y022LS12MeGGXuR+i11GQXw4b3tNg4h/gqr6EPCQiJwP3AxcEqJyHwMeA+eqCkWZgdI6M5nBnZsxY+kmrj22V0NeOvpISoOjbnB/3I/+5ERk0Ysw9iYY/jPXwV5X/EVjxBVw4j0mGvVl6EXuSf3DWyAl24UqifbPdEeuW2Fz6VtuDRLUtWwPn+LEosNQ6+wOMeEUjvVAZ7/9Tl5adUwFHgng3GDKjBjj+rXlb+/nsCmvgLZZ1hwmsx2c6t3gP/gDvHsDfPkYHP8nb3ndIG9OJhrh44hrnXh8cp8b+DDutkhbVBFVt8Lh0rfdKKifvDlEbQe6B5J+p7jYcPZ7CBvhFI75QC8R6Y67uZ8HVIjqJyK9VNW3LN7JgG97GvCiiNyH6xzvBXwJSG1lRgvH9XfCMXPpZs4f2bCusqim/SFw8TT44T1343/pXOh+lBuV1W5gYGWouphZnz8EI66EE/9qN4lQc+ytfuLRDI74VWTtUYUNX7lWxdK3YNsKl955pHv46DvBDS82GoSwCYeqFovIFOB9IB54SlUXi8gdwAJVnQZMEZFxQBGwA89N5eV7BdfpXQxco6olAFWVGa461IdebTLo3CKVGUs3mXBURgT6nOiWOF3wlFt3/dExMORCOOYWF96kOkw0GgYRN5y5YJebF5PSDIaFxIscOCXF8ONnTiiWvQ156yEuwcV6O+wXLmhoZruGtckAwjgcN5po6OG4Pv741mJe+OJHFt16HGlJEe9Oil727YA597rAifFJMOZ6559OTK2YT9UN8/38YRh5FYz/i4lGuCne79alX/kRnP2MmxwX1usVuuCLS6e5wRR7t0FCCvQ81rmgep8AaS3Ca4NRRnXDcU04wsi8FVs5/4kveOyiYRx/sD0Z1cq2lS6+1NK3IKuT860POMt1bJpoRI79e11Ykg1fwfkvu9DsoaQw38WIWvY2/PAB7M+H5CwnEv1OcS3TxjavJEYw4YiAcBSVlDL0zg85cUA77jlrUINfP2bJ/dSJxMZFbkTMCX92T6CfP+yW2h1/t4lGQ7NvJzwzwa0lc/H/oPOh9Stv73bXolj6lmvNlBRCWivnfuo3EbqPgYTkkJhu1J1ITABs8iTGxzG2TxtmLt1MSakSH2c3u4DodgRcPgu+ewVm/NGFhAATjUiS2sxF1H3qBBdR92fvuhAdwZC3wa11sXSaezjQEteyHH6pN8fisNibN9JEMeEIM+P6teGtbzawaO1OhnVtHmlzYoe4OBh0nnv6/OIRQGD09SYakSSjjYuo+9QJznV16Xu1j2TattK5oJa+Bevmu7RWvWH0dU4s2g+27zQGMeEIM2N7tyEhTpi5dJMJR11ISoMxv4m0FYaP5l2deDw9Hp47DS59v+LIJlXYtLh82Oxmb9Bj+8FuxFy/U6B1nwgYboQSE44wk52WyIjuLZixdBM3ju8baXMMo/606QsXvA7/OcW1PCa/4+ZVLJ3mxGJHLiDQ5XA44W4XRLCZDUlvTJhwNADH9mvLnW8vYc22PXRtaaNDjEZAp2Ew6UV44Wy4tzeUFkFcIvQ4yrkU+5zkXFtGo8SEowEY168Nd769hBlLN3PZaJvdajQSeoyFc593UZB7nQC9j3fxrYxGjwlHA9C1ZTq922Ywc+kmEw6jcdH7BPcymhQWMrKBGNevLV+s3s6uvUWRNsUwDKNemHA0EMf2a0tJqTL7h80B5VdV1m7fy3+/Wsfd7y5lU15BmC00DMMIDHNVNRCDOzejVUYSM5Zu5tTBHQ84XlxSytKN+SxYs50FuTuYn7udzfmFZcc/XbGVV68cRWqSTZAyDCOymHA0EPFxwjF92/Du9z9RVFJKYXEpi37cyfzc7SxYs52vf9zJ3v0lAHRslsqoni0Z1q0Fh3Zrzrrt+7j8uQX85tVFPDhpKHE2A90wjAhiwtGAjOvXllcWrOOEf8whd9seShXiBPq2y+LsYZ0Y1q0Fw7s2p0OzilFh+7bL4g8n9eNP7yzl/tY/8OvjbQKVYRiRw4SjARnTqzWDOmWTlpTAhEPaM7xbC4Z0aUZmSu3Lp142ujvLN+3mgY9W0LNNRpXuLsMwjIbAhKMBSU2K539TRtfpXBHhztMGsHrbHm547Vs6t0hjaBcLYWIYRsNjo6piiKSEOB69cBjtslK44tmFrN+5L9ImGYbRBDHhiDFapCfx5CXDKSwq4ef/WcCewuJIm2QYRhPDhCMG6dU2k3+dP4Scn/K47uVFlJY2/sW4DMOIHkw4YpSxfdpw64T+fLhkE3/7ICfS5hiG0YSwzvEY5pJR3Vi+eTePzF7JQa0zOHNYp0ibZBhGE8BaHDGMiHD7xIMZ1bMlN/33Oxbkbo+0SYZhNAFMOGKcxPg4Hr5gKB2bp3LlcwtZu31vpE0yDKORY8LRCGiWlsQTlwynqKSUn/9nAfkFFoHXMIzwYcLRSOjZOoOHLxjGii27+dXURZTYSCvDMMKECUcjYnSvVtw+8WA+WraZu95ZSlFJaaRNMgyjEWKjqhoZFx3WlRWb8nnq09U8//kaerfL4OD22RzcMYuDO2TRr30WaUn2tRuGUXfsDtIIufWUgzmsR0sWrdvJ4vV5fLDkJ15esBYAEejRKp2DO2RzcIessvfm6UkRttowjFjBhKMREh8nnDiwPScObA+41QQ37ipg8YY8Fm/YxeINeSxcs4Np32woO6dDdgr9O2QzoGO5mLTPTkHE1v4wDKMiJhxNABGhQ7NUOjRL5bj+bcvSd+zZX0FMFm/Yxcxlm1CvX715WmKZiPT3WifdW6UTbwtJGUaTxoSjCdM8PYnRvVoxulersrQ9hcUs+ynPCcn6PBZv3MXTn+ay3+toT0uKp1/7LM/N5cSkV9sMkhNsSVvDaCqIauMftjl8+HBdsGBBpM2IWfYXl7Ji8+4KLZMlG/LY4y11mxgv9GqTWS4mHbPp1z6LjGR7LjGMWEZEFqrq8APSTTiMulBaqqzZvtdPTPJYvH4X2/bsB1wnfLeW6Z6LK4sBnsurZUZyhC03DCNQqhMOeyQ06kRcnNC9VTrdW6Uz4ZAOgOuE35RXWKFl8s3anbzz7cay89plpZS1TPp7YtKpeap1whtGDBFW4RCR8cA/gXjgCVX9S6XjvwZ+DhQDW4BLVXWNd+yvwMle1jtV9WUv/RngKGCXd2yyqi4KZz2MwBAR2mWn0C47hWP7lXfC79y7nyW+VoknKrNyNuOb3J6dmlihz+TgDln0aJ1hnfCGEaWETThEJB54CDgOWAfMF5FpqrrEL9vXwHBV3SsiVwP3AOeKyMnAUGAwkAzMFpF3VTXPO+8GVX0tXLYboaVZWhKjDmrFqIPKO+H37S8p74T3xOQ/n61hf7HrhE9JjKNvu3Ix6ds+k56tMshOS4xUNQzD8Ahni2MEsEJVVwGIyFTgVKBMOFR1ll/+z4ELve3+wBxVLQaKReRbYDzwShjtNRqQ1KR4hnRpzpAuzcvSikpKWblltxvN5QnKtEUbeOGLH8vytEhPKnORdW+VTs/W6XRvlUHXlmmkJNrILsNoCMIpHB2BtX7764CRNeS/DHjX2/4GuE1E/g6kAUfjJzjAXSJyKzAT+J2qFlYuTESuAK4A6NKlS13rYDQgifGuldG3XRZnDnNppaXK2h17Wb5pN6u37mHV1t2s2rKHOT9s4bWF68rOFYEO2an0aO0EpUerdLq3zqBHq3Q6NEs1t5dhhJCo6BwXkQuB4bi+C1T1AxE5FJiH6/v4DCjxst8E/AQkAY8B/wfcUblMVX3MO87w4cMb/9CxRkpcnNC1ZTpdW6YfcGx3YTG5W/ewauseVm1xwrJ66x7e+Go9+YXFZfmS4uPo2jLNCYonJt09gWmZnmQd84YRJOEUjvVAZ7/9Tl5aBURkHPAH4Cj/loOq3gXc5eV5EfjBS/cN0SkUkaeB34bFeiPqyUhOYEDHbAZ0zK6Qrqps3b3fExLXQlnlCcysnM0UlZQ/R2SmJNDDExR/F1j3Vumk2zwUw6iScP4z5gO9RKQ7TjDOA873zyAiQ4B/A+NVdbNfejzQTFW3icghwCHAB96x9qq6Udxj4mnA92GsgxGDiAitM5NpnZnMiO4tKhwrLillw86CMpeXr5Xy5ertvPF1xeeatlnJ9GiVQffWnuvLe3VukUZivK1IYDRdwiYcqlosIlOA93HDcZ9S1cUicgewQFWnAX8DMoBXPXfBj6o6EUgE5nppecCFXkc5wAsi0hoQYBFwVbjqYDQ+EuLj6NIyjS4t0xjbp+KxfftLWLN9T5mguPfdvPvdRnbsLV9VMSFO6NIirbx1UtavkkHbrGRzfRmNHps5bhgBsGPPflZvKxcTn7DkbttDQVH5gllpSfFlglLel+LcYNmp4RlKrKoUlShFJaUUlyj7S0opLvXb9o65l1JcUkpRqVJU7PLt99LK87t8RaX+5/rK98tfqmUxzDKSEshISSA9OYHMZPeekZJARnI8GcmJpCfHk+m9Z6QkWGyzGMFmjhtGPWienkTz9CSG+g0fBjfq66e8gjJBWeW5vr5bv4vp323EfwXfVhluKHHXlukkxgv7i7XSDd7vBl164A27wrHiUopKXVq4lwkWcSPeEuOExIQ4EuLiSIwXEuPjSIh3ras9hcXsKSxht9+ghJpIjBcnLn6vMrExEYp6TDgMox7ExZWHrPePMgxQWFzC2u17K/SlrNq6h0+Wb6VU1d2M44WE+DgS4oSkBPeeGB9HamI8mSkJZXkS490NOylBSIhzN+wk78bt8pSfW35T9z/X3fQT4/zPqSJ/XLkg+MoNZihzaamyt6iE3QXF7C50rz2FxeQXuPfdhRXT/fPt3LuftTv2lqX7gmjWRmK8lAuP71VZeCqlmwjVDxMOwwgTyQnxHNQmk4PaZEbalAYjLk7KbtL1pbRU2bPf15IpYndhuSDVJkI79uznx+11E6HMlEQykhPITEnw3hPJTEkoe2UkV9z3z5+ZnEhGSkKjnzdkwmEYRlQSFyfeTTsRSKlXWTWJkL8Q+VpG+QVF5BcUk19YzPqd+9hd6O0XFAfkGkxLij9QVDxhyUxJKGvdJMYLyQmuZZfk955Uab/GfPFxxDWwUJlwGIbR6AmVCKkqBUWlTlg8ockvKGK3Jyp5BUVlArS7oJh8P8HZsHNf2bG9AbaAAiU+Tkj03Jc+QUn03p+4ZHiVE2jrgwmHYRhGgIgIqUnxpCbF06Ye5ZSUKvuLS9lfUsr+4tKyUW8V07TsmH8+33thpTzlaaUVzgtHDDcTDsMwjAYmPs4TIGKzM96mvxqGYRhBYcJhGIZhBIUJh2EYhhEUJhyGYRhGUJhwGIZhGEFhwmEYhmEEhQmHYRiGERQmHIZhGEZQNIn1OERkC7AmgKytgK1hNqehaEx1AatPNNOY6gKNqz71rUtXVW1dObFJCEegiMiCqhYtiUUaU13A6hPNNKa6QOOqT7jqYq4qwzAMIyhMOAzDMIygMOGoyGORNiCENKa6gNUnmmlMdYHGVZ+w1MX6OAzDMIygsBaHYRiGERQmHIZhGEZQmHAAIjJeRHJEZIWI/C7S9gSCiDwlIptF5Hu/tBYi8qGILPfem3vpIiIPePX7VkSGRs7yAxGRziIyS0SWiMhiEfmVlx6r9UkRkS9F5BuvPn/00ruLyBee3S+LSJKXnuztr/COd4toBapAROJF5GsRedvbj+W65IrIdyKySEQWeGkx+VsDEJFmIvKaiCwTkaUicni469PkhUNE4oGHgBOB/sAkEekfWasC4hlgfKW03wEzVbUXMNPbB1e3Xt7rCuCRBrIxUIqB36hqf+Aw4BrvO4jV+hQCx6jqIGAwMF5EDgP+CvxDVQ8CdgCXefkvA3Z46f/w8kUbvwKW+u3Hcl0AjlbVwX5zHGL1twbwT+A9Ve0LDMJ9T+Gtj6o26RdwOPC+3/5NwE2RtitA27sB3/vt5wDtve32QI63/W9gUlX5ovEF/A84rjHUB0gDvgJG4mbwJnjpZb874H3gcG87wcsnkbbdrw6dvJvPMcDbgMRqXTy7coFWldJi8rcGZAOrK3/G4a5Pk29xAB2BtX7767y0WKStqm70tn8C2nrbMVNHz7UxBPiCGK6P59pZBGwGPgRWAjtVtdjL4m9zWX2847uAlg1qcM3cD9wIlHr7LYndugAo8IGILBSRK7y0WP2tdQe2AE97rsQnRCSdMNfHhKORou5xIqbGWotIBvA6cJ2q5vkfi7X6qGqJqg7GPa2PAPpG1qK6ISITgM2qujDStoSQ0ao6FOe2uUZEjvQ/GGO/tQRgKPCIqg4B9lDulgLCUx8TDlgPdPbb7+SlxSKbRKQ9gPe+2UuP+jqKSCJONF5Q1f96yTFbHx+quhOYhXPnNBORBO+Qv81l9fGOZwPbGtbSajkCmCgiucBUnLvqn8RmXQBQ1fXe+2bgDZywx+pvbR2wTlW/8PZfwwlJWOtjwgHzgV7eKJEk4DxgWoRtqivTgEu87UtwfQW+9Iu9ERWHAbv8mrERR0QEeBJYqqr3+R2K1fq0FpFm3nYqrr9mKU5AzvKyVa6Pr55nAR95T4kRR1VvUtVOqtoN99/4SFUvIAbrAiAi6SKS6dsGjge+J0Z/a6r6E7BWRPp4SccCSwh3fSLduRMNL+Ak4AecH/oPkbYnQJtfAjYCRbinjstwvuSZwHJgBtDCyyu4kWMrge+A4ZG2v1JdRuOa0t8Ci7zXSTFcn0OAr736fA/c6qX3AL4EVgCvAsleeoq3v8I73iPSdaimXmOBt2O5Lp7d33ivxb7/e6z+1jwbBwMLvN/bm0DzcNfHQo4YhmEYQWGuKsMwDCMoTDgMwzCMoDDhMAzDMILChMMwDMMIChMOwzAMIyhMOBo5InKaiKiIRHTmsohcJyJpQZ4zRlx02UXefIiYRESuEpGLg8jfTUTO99ufLCIP1uP6fb3P8GsR6Ski84I8v9rvrvIxEdldVzuDsGeseFF6jchgwtH4mQR84r1HkutwAf+C4QLgbnVRTPeF3qSK+M2EDimq+qiqPhvEKd2A82vLFASnAa+p6hBVXamqoypnqKXu11H9d1fTsSoJ1+ccKqLdvqgg0pNX7BW+F5CBCyfQGy86ppc+FvgYN5t0FfAX3E36S9ykoJ5evm7AR7iJRTOBLl76M8BZfuXt9it3Ni7swTLgBdyEo2uB/V7Zs6qw81jchLnvgKeAZODnwHZc5M8XKuXvhpuJ/ThuEtcHQKp3rCfwHrAQmAv0DcDmubgZtT/gJrA97dnyNS78NsBk4L9e2cuBe7z0eK/s771zrq+ifrcDv/W2Z+NCjX/pXW9MFfk/xwUHXARcX921vbzHA5/hIvC+CmRUKuskXJC79b7Pvoa6pwPv4CbHfQ+cW9N3V9UxYDdwl1fG57hge77P/1Fc8Mr7avieWuNCz8z3XkdU8fmMpXwi4giv/l8D84A+XvocYLDfOZ/gQo6n435jX3rnnOr3/U7D/d4/xkWUneN9B99X9T015VfEDbBXGL9cJwZPetvzgGHe9lhgp/fnSPZuKn/0jv0KuN/bfgu4xNu+FHjT236G6m/Cu3Dxb+K8P/Ro71gulUJZe+kpuGidvb39Z3FBDg+4jt853XBreAz29l8BLvS2ZwK9vO2RuJAXtdm8B+ju7f8GeMrb7gv86Nk4GSey2d7+GlzMn2HAh37lNqvC3tupKBx/97ZPAmZUkX8s3o3R26/u2q28m1u6l+//8GapV3f9Wup+JvC4X77smr67qo7hIgCc4m3fA9zs9/m/DcTX8j29SPlvpgsuDE21nw+QRXl493HA6972JZT/jnsDC7ztP1P+W2lGuWBOxkVg8M2w/g3ls8rjgcxI/5+j6WVNssbNJFxAOnAB6ibhnvAA5qsXo0ZEVuKe2sE9PR7tbR8OnOFtP4e7EdTGl6q6zit3Ee4m/0kN+fsAq1X1B2//P8A1uFDeNbFaVRd52wuBbl503VHAqy78FeCEMRCbV3vbo4F/AajqMhFZg7vxgFsYZxeAiCwBuuJaPD1E5F+4p/UPqB1fEMeFuM8nEKq6djPc4mOfevVNwol1MPjX/Tvg7yLyV9yNeW6QZYFrgfj6Hxbi4nT5eFVVS2r5nsYB/f3Ss0QkQ1Wr6zvJBv4jIr1wopXouxZwi4jcgHvoecZLPx4XtPG33n4KTqDAPQBs97bnA095wTff9PutGWDC0VgRkRa4SKYDRURxT03q/ZHArVLno9Rvv5TafxfFeP1jIhKHu2H58C+3JICy6krl66R6Nu1UF868MjXZvKeO10xQ1R0iMgg4AbgKOAd3owqknGA+n6o+V8Hd7OrTf1VWd1X9wVtK9CTgTyIyU1XvCLK8IvUe0zmwfr5r1fQ9xQGHqWpBgNe7E+cmO91by2U2gKruFZEPgVNx38kwL78AZ6pqjn8hIjKSip/FHC/c+snAMyJynwbXT9Wosc7xxstZwHOq2lVVu6lqZ1x/wZggypiHi4gKzu3lewLNpfyPOJHyp7yayAcyq0jPwbUWDvL2L8L5mING3Roeq0XkbChbX3lQkDbPxdUVEemNexrNqSYvItIKiFPV14GbcSGt60t1n1VlPgeO8H12XuTX3rWcUy0i0gHYq6rPA3+jvC412ROorWXU8j19APzSz6bBtRSXTXlY8MmVjj0BPIBrXe/w0t4HfulFZEZEhlRVqIh0BTap6uNeOVG31ngkMeFovEzCrTXgz+sEN7rql8DPRORb3A39V17648BRIvINzp0VyBP7Y8B7IjLLP9F7svwZzm3xHa7F82gQNlbmAuAyz7bFuCfOYGx+GIjzbHkZmKyqhdXkBbd62mzPLfc8bunh+vItUCIi34jI9dVlUtUtuJvlS9539Bn1WzBqIPClV5fbgD956VV+dwEcq4nqvqdrgeEi8q3nkruqlnLuAe4Wka+p1HpTt/hUHm6wg487cQ8N34rIYm+/KsYC33jlnku5y9cAi45rGEbjxGtBzcaN2CqtJbsRBNbiMAyj0eFNuPwCNzLKRCPEWIvDMAzDCAprcRiGYRhBYcJhGIZhBIUJh2EYhhEUJhyGYRhGUJhwGIZhGEHx/22Sy3B57j/VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(parameters, losses3, label = \"Training Error\")\n",
    "plt.plot(parameters, val_losses3, label = \"Validation Error\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss Evolution (9 input variables)\")\n",
    "plt.xlabel(\"Amount of neurons in the first three layers\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5910 - accuracy: 0.7259 - val_loss: 0.4447 - val_accuracy: 0.8427\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8436 - val_loss: 0.4065 - val_accuracy: 0.8497\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8525 - val_loss: 0.3732 - val_accuracy: 0.8470\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8499 - val_loss: 0.3535 - val_accuracy: 0.8492\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8529 - val_loss: 0.3456 - val_accuracy: 0.8504\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8520 - val_loss: 0.3433 - val_accuracy: 0.8500\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8548 - val_loss: 0.3383 - val_accuracy: 0.8509\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8528 - val_loss: 0.3360 - val_accuracy: 0.8514\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8547 - val_loss: 0.3341 - val_accuracy: 0.8521\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8541 - val_loss: 0.3331 - val_accuracy: 0.8513\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5232 - accuracy: 0.8114 - val_loss: 0.3944 - val_accuracy: 0.8493\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3755 - accuracy: 0.8492 - val_loss: 0.3502 - val_accuracy: 0.8519\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8526 - val_loss: 0.3412 - val_accuracy: 0.8524\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3367 - accuracy: 0.8531 - val_loss: 0.3416 - val_accuracy: 0.8493\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3317 - accuracy: 0.8554 - val_loss: 0.3336 - val_accuracy: 0.8518\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8518 - val_loss: 0.3350 - val_accuracy: 0.8513\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3315 - accuracy: 0.8526 - val_loss: 0.3304 - val_accuracy: 0.8526\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3283 - accuracy: 0.8525 - val_loss: 0.3300 - val_accuracy: 0.8524\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3262 - accuracy: 0.8536 - val_loss: 0.3272 - val_accuracy: 0.8520\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3246 - accuracy: 0.8545 - val_loss: 0.3282 - val_accuracy: 0.8516\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5083 - accuracy: 0.8019 - val_loss: 0.3579 - val_accuracy: 0.8511\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8552 - val_loss: 0.3436 - val_accuracy: 0.8477\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8543 - val_loss: 0.3341 - val_accuracy: 0.8503\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8560 - val_loss: 0.3297 - val_accuracy: 0.8506\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8557 - val_loss: 0.3261 - val_accuracy: 0.8520\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8533 - val_loss: 0.3251 - val_accuracy: 0.8513\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8537 - val_loss: 0.3233 - val_accuracy: 0.8512\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3191 - accuracy: 0.8564 - val_loss: 0.3236 - val_accuracy: 0.8520\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3226 - accuracy: 0.8517 - val_loss: 0.3214 - val_accuracy: 0.8518\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3197 - accuracy: 0.8530 - val_loss: 0.3216 - val_accuracy: 0.8505\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4731 - accuracy: 0.8170 - val_loss: 0.3438 - val_accuracy: 0.8517\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3405 - accuracy: 0.8515 - val_loss: 0.3372 - val_accuracy: 0.8511\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8526 - val_loss: 0.3292 - val_accuracy: 0.8517\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3314 - accuracy: 0.8500 - val_loss: 0.3257 - val_accuracy: 0.8526\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3279 - accuracy: 0.8529 - val_loss: 0.3237 - val_accuracy: 0.8527\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3198 - accuracy: 0.8573 - val_loss: 0.3230 - val_accuracy: 0.8515\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3232 - accuracy: 0.8528 - val_loss: 0.3235 - val_accuracy: 0.8512\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3204 - accuracy: 0.8514 - val_loss: 0.3218 - val_accuracy: 0.8514\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3191 - accuracy: 0.8543 - val_loss: 0.3204 - val_accuracy: 0.8513\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3175 - accuracy: 0.8549 - val_loss: 0.3208 - val_accuracy: 0.8516\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4601 - accuracy: 0.8305 - val_loss: 0.3490 - val_accuracy: 0.8497\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3410 - accuracy: 0.8488 - val_loss: 0.3373 - val_accuracy: 0.8510\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8521 - val_loss: 0.3284 - val_accuracy: 0.8510\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8546 - val_loss: 0.3263 - val_accuracy: 0.8508\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3204 - accuracy: 0.8551 - val_loss: 0.3231 - val_accuracy: 0.8513\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3228 - accuracy: 0.8529 - val_loss: 0.3230 - val_accuracy: 0.8507\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3168 - accuracy: 0.8555 - val_loss: 0.3211 - val_accuracy: 0.8516\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3200 - accuracy: 0.8525 - val_loss: 0.3201 - val_accuracy: 0.8525\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3129 - accuracy: 0.8559 - val_loss: 0.3223 - val_accuracy: 0.8503\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3142 - accuracy: 0.8560 - val_loss: 0.3182 - val_accuracy: 0.8520\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4401 - accuracy: 0.8305 - val_loss: 0.3377 - val_accuracy: 0.8516\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3375 - accuracy: 0.8509 - val_loss: 0.3340 - val_accuracy: 0.8517\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3279 - accuracy: 0.8533 - val_loss: 0.3256 - val_accuracy: 0.8506\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3232 - accuracy: 0.8508 - val_loss: 0.3255 - val_accuracy: 0.8508\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3215 - accuracy: 0.8532 - val_loss: 0.3219 - val_accuracy: 0.8520\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3188 - accuracy: 0.8545 - val_loss: 0.3200 - val_accuracy: 0.8516\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3190 - accuracy: 0.8512 - val_loss: 0.3195 - val_accuracy: 0.8518\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3222 - accuracy: 0.8516 - val_loss: 0.3191 - val_accuracy: 0.8525\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3173 - accuracy: 0.8531 - val_loss: 0.3199 - val_accuracy: 0.8508\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3184 - accuracy: 0.8524 - val_loss: 0.3189 - val_accuracy: 0.8516\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 5ms/step - loss: 0.4152 - accuracy: 0.8416 - val_loss: 0.3415 - val_accuracy: 0.8479\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3344 - accuracy: 0.8515 - val_loss: 0.3256 - val_accuracy: 0.8493\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3250 - accuracy: 0.8507 - val_loss: 0.3222 - val_accuracy: 0.8519\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3199 - accuracy: 0.8524 - val_loss: 0.3211 - val_accuracy: 0.8518\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3221 - accuracy: 0.8518 - val_loss: 0.3228 - val_accuracy: 0.8522\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3219 - accuracy: 0.8519 - val_loss: 0.3209 - val_accuracy: 0.8509\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3120 - accuracy: 0.8573 - val_loss: 0.3205 - val_accuracy: 0.8513\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3171 - accuracy: 0.8551 - val_loss: 0.3182 - val_accuracy: 0.8523\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3175 - accuracy: 0.8545 - val_loss: 0.3193 - val_accuracy: 0.8510\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3182 - accuracy: 0.8505 - val_loss: 0.3185 - val_accuracy: 0.8521\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.4057 - accuracy: 0.8407 - val_loss: 0.3368 - val_accuracy: 0.8494\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3292 - accuracy: 0.8546 - val_loss: 0.3246 - val_accuracy: 0.8507\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3233 - accuracy: 0.8528 - val_loss: 0.3243 - val_accuracy: 0.8520\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3199 - accuracy: 0.8540 - val_loss: 0.3276 - val_accuracy: 0.8510\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3204 - accuracy: 0.8528 - val_loss: 0.3213 - val_accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3192 - accuracy: 0.8526 - val_loss: 0.3204 - val_accuracy: 0.8507\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3166 - accuracy: 0.8545 - val_loss: 0.3234 - val_accuracy: 0.8521\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3173 - accuracy: 0.8553 - val_loss: 0.3210 - val_accuracy: 0.8504\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3183 - accuracy: 0.8513 - val_loss: 0.3180 - val_accuracy: 0.8515\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3161 - accuracy: 0.8554 - val_loss: 0.3193 - val_accuracy: 0.8506\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.4047 - accuracy: 0.8393 - val_loss: 0.3338 - val_accuracy: 0.8512\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.3255 - accuracy: 0.8522 - val_loss: 0.3284 - val_accuracy: 0.8502\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.3243 - accuracy: 0.8503 - val_loss: 0.3224 - val_accuracy: 0.8506\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.3179 - accuracy: 0.8535 - val_loss: 0.3245 - val_accuracy: 0.8515\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.3189 - accuracy: 0.8526 - val_loss: 0.3200 - val_accuracy: 0.8518\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.3190 - accuracy: 0.8540 - val_loss: 0.3187 - val_accuracy: 0.8525\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.3160 - accuracy: 0.8553 - val_loss: 0.3203 - val_accuracy: 0.8515\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.3179 - accuracy: 0.8511 - val_loss: 0.3208 - val_accuracy: 0.8499\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.3173 - accuracy: 0.8537 - val_loss: 0.3181 - val_accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.3172 - accuracy: 0.8518 - val_loss: 0.3182 - val_accuracy: 0.8517\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.4060 - accuracy: 0.8366 - val_loss: 0.3294 - val_accuracy: 0.8495\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.3274 - accuracy: 0.8509 - val_loss: 0.3221 - val_accuracy: 0.8523\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3199 - accuracy: 0.8534 - val_loss: 0.3246 - val_accuracy: 0.8509\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3213 - accuracy: 0.8518 - val_loss: 0.3234 - val_accuracy: 0.8521\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3177 - accuracy: 0.8536 - val_loss: 0.3200 - val_accuracy: 0.8520\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3180 - accuracy: 0.8542 - val_loss: 0.3218 - val_accuracy: 0.8495\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 0.3172 - accuracy: 0.8523 - val_loss: 0.3193 - val_accuracy: 0.8519\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3187 - accuracy: 0.8534 - val_loss: 0.3232 - val_accuracy: 0.8505\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 0.3182 - accuracy: 0.8512 - val_loss: 0.3203 - val_accuracy: 0.8507\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3183 - accuracy: 0.8528 - val_loss: 0.3220 - val_accuracy: 0.8504\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.3944 - accuracy: 0.8370 - val_loss: 0.3323 - val_accuracy: 0.8515\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3310 - accuracy: 0.8511 - val_loss: 0.3240 - val_accuracy: 0.8499\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 0.3236 - accuracy: 0.8497 - val_loss: 0.3214 - val_accuracy: 0.8508\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.3168 - accuracy: 0.8529 - val_loss: 0.3216 - val_accuracy: 0.8512\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.3198 - accuracy: 0.8519 - val_loss: 0.3197 - val_accuracy: 0.8521\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.3128 - accuracy: 0.8551 - val_loss: 0.3189 - val_accuracy: 0.8520\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.3154 - accuracy: 0.8547 - val_loss: 0.3221 - val_accuracy: 0.8518\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 0.3191 - accuracy: 0.8521 - val_loss: 0.3214 - val_accuracy: 0.8520\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.3177 - accuracy: 0.8536 - val_loss: 0.3199 - val_accuracy: 0.8510\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.3156 - accuracy: 0.8550 - val_loss: 0.3194 - val_accuracy: 0.8515\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.3968 - accuracy: 0.8364 - val_loss: 0.3325 - val_accuracy: 0.8515\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.3286 - accuracy: 0.8501 - val_loss: 0.3272 - val_accuracy: 0.8501\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 0.3234 - accuracy: 0.8523 - val_loss: 0.3229 - val_accuracy: 0.8517\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.3241 - accuracy: 0.8506 - val_loss: 0.3206 - val_accuracy: 0.8511\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 6s 26ms/step - loss: 0.3187 - accuracy: 0.8520 - val_loss: 0.3221 - val_accuracy: 0.8513\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.3191 - accuracy: 0.8547 - val_loss: 0.3215 - val_accuracy: 0.8505\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.3209 - accuracy: 0.8501 - val_loss: 0.3320 - val_accuracy: 0.8481\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.3157 - accuracy: 0.8529 - val_loss: 0.3203 - val_accuracy: 0.8517\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.3169 - accuracy: 0.8529 - val_loss: 0.3200 - val_accuracy: 0.8513\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.3127 - accuracy: 0.8551 - val_loss: 0.3192 - val_accuracy: 0.8507\n"
     ]
    }
   ],
   "source": [
    "parameters = [10, 20, 30, 50, 75, 100, 200, 300, 400, 500, 550, 600]\n",
    "losses4 = []\n",
    "val_losses4 = []\n",
    "for para in parameters:\n",
    "    model = keras.Sequential([\n",
    "     keras.layers.Dense(para, activation = LeakyReLU(alpha=alpha), input_shape=(4,)),\n",
    "     keras.layers.Dense(para, activation = LeakyReLU(alpha=alpha)),\n",
    "     keras.layers.Dense(para, activation = LeakyReLU(alpha=alpha)),\n",
    "     keras.layers.Dense(1, activation = \"sigmoid\")]\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]) \n",
    "    history4 = model.fit(X2, Y, batch_size=200, epochs=10, validation_split=0.5)\n",
    "    losses4.append(history4.history['loss'][-1])\n",
    "    val_losses4.append(history4.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(parameters, losses4, label = \"Training Error\")\n",
    "plt.plot(parameters, val_losses4, label = \"Validation Error\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss Evolution (4 input variables)\")\n",
    "plt.xlabel(\"Amount of neurons in the first three layers\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implenting the final model and run the prediction of the move directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Leaky ReLU does not come along with big improvements regrading the losses, we use the ReLU function for the activation of our final model. Moreover, we choose the number of neurons to $100$ due to the fact that the plots indicate not a much lower loss for a higher number and so we can benefit from a lower computation time. Lastly, we take the volume data and the information of the past moves as our inputs since this does not lead to any overfitting as displayed by the validation loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup of final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 5ms/step - loss: 0.4439 - accuracy: 0.8110 - val_loss: 0.3257 - val_accuracy: 0.8570\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3197 - accuracy: 0.8592 - val_loss: 0.3081 - val_accuracy: 0.8633\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3034 - accuracy: 0.8658 - val_loss: 0.3103 - val_accuracy: 0.8588\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3020 - accuracy: 0.8648 - val_loss: 0.3074 - val_accuracy: 0.8607\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3034 - accuracy: 0.8618 - val_loss: 0.3013 - val_accuracy: 0.8638\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2938 - accuracy: 0.8676 - val_loss: 0.3004 - val_accuracy: 0.8645\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3009 - accuracy: 0.8622 - val_loss: 0.3036 - val_accuracy: 0.8613\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2988 - accuracy: 0.8644 - val_loss: 0.3013 - val_accuracy: 0.8640\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2978 - accuracy: 0.8644 - val_loss: 0.3002 - val_accuracy: 0.8637\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2910 - accuracy: 0.8688 - val_loss: 0.2999 - val_accuracy: 0.8641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1654a3400>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelfinal = keras.Sequential([\n",
    "     keras.layers.Dense(100, activation = 'relu', input_shape=(9,)),\n",
    "     keras.layers.Dense(100, activation = 'relu'),\n",
    "     keras.layers.Dense(100, activation = 'relu'),\n",
    "     keras.layers.Dense(1, activation = \"sigmoid\")]\n",
    "    )\n",
    "modelfinal.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]) \n",
    "modelfinal.fit(X, Y, batch_size=200, epochs=10, validation_split=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock tick prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we save the unlabelled dataset in a Pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sell Side Price LV1</th>\n",
       "      <th>Sell Side Volume LV1</th>\n",
       "      <th>Buy Side Price LV1</th>\n",
       "      <th>Buy Side Volume LV1</th>\n",
       "      <th>Sell Side Price LV2</th>\n",
       "      <th>Sell Side Volume LV2</th>\n",
       "      <th>Buy Side Price LV2</th>\n",
       "      <th>Buy Side Volume LV2</th>\n",
       "      <th>Past Move 1</th>\n",
       "      <th>Past Move 2</th>\n",
       "      <th>Past Move 3</th>\n",
       "      <th>Past Move 4</th>\n",
       "      <th>Past Move 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356300</td>\n",
       "      <td>2200</td>\n",
       "      <td>356100</td>\n",
       "      <td>1745</td>\n",
       "      <td>356400</td>\n",
       "      <td>1845</td>\n",
       "      <td>356000</td>\n",
       "      <td>1745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>354400</td>\n",
       "      <td>13398</td>\n",
       "      <td>354300</td>\n",
       "      <td>1</td>\n",
       "      <td>354500</td>\n",
       "      <td>13605</td>\n",
       "      <td>354200</td>\n",
       "      <td>10766</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359600</td>\n",
       "      <td>6702</td>\n",
       "      <td>359400</td>\n",
       "      <td>24404</td>\n",
       "      <td>359700</td>\n",
       "      <td>4801</td>\n",
       "      <td>359300</td>\n",
       "      <td>9986</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>358600</td>\n",
       "      <td>4857</td>\n",
       "      <td>358500</td>\n",
       "      <td>300</td>\n",
       "      <td>358700</td>\n",
       "      <td>3498</td>\n",
       "      <td>358400</td>\n",
       "      <td>3577</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>365600</td>\n",
       "      <td>3500</td>\n",
       "      <td>365400</td>\n",
       "      <td>3047</td>\n",
       "      <td>365700</td>\n",
       "      <td>3301</td>\n",
       "      <td>365300</td>\n",
       "      <td>2045</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sell Side Price LV1  Sell Side Volume LV1  Buy Side Price LV1  \\\n",
       "0               356300                  2200              356100   \n",
       "1               354400                 13398              354300   \n",
       "2               359600                  6702              359400   \n",
       "3               358600                  4857              358500   \n",
       "4               365600                  3500              365400   \n",
       "\n",
       "   Buy Side Volume LV1  Sell Side Price LV2  Sell Side Volume LV2  \\\n",
       "0                 1745               356400                  1845   \n",
       "1                    1               354500                 13605   \n",
       "2                24404               359700                  4801   \n",
       "3                  300               358700                  3498   \n",
       "4                 3047               365700                  3301   \n",
       "\n",
       "   Buy Side Price LV2  Buy Side Volume LV2  Past Move 1  Past Move 2  \\\n",
       "0              356000                 1745            0            0   \n",
       "1              354200                10766            0            0   \n",
       "2              359300                 9986            1            0   \n",
       "3              358400                 3577            1            1   \n",
       "4              365300                 2045            0            0   \n",
       "\n",
       "   Past Move 3  Past Move 4  Past Move 5  \n",
       "0            0            1            0  \n",
       "1            0            0            1  \n",
       "2            1            0            1  \n",
       "3            0            0            0  \n",
       "4            0            0            0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv(\"Dataset_B_nolabels.csv\", names = data.columns[1:]) \n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reshaping the input variables properly, we use the model implemented above to predict the next move direction. Note that we use the `np.round()` method to end up with either $0$ or $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2 = len(data2.index)\n",
    "avg = np.mean([np.mean(data2[\"Sell Side Volume LV1\"]), np.mean(data2[\"Buy Side Volume LV1\"]), np.mean(data2[\"Sell Side Volume LV2\"]), np.mean(data2[\"Buy Side Volume LV2\"])])\n",
    "a1 = np.reshape([data2[\"Sell Side Volume LV1\"].to_numpy()], (N2,1)) / avg \n",
    "a2 = np.reshape([data2[\"Buy Side Volume LV1\"].to_numpy()], (N2,1)) / avg \n",
    "a3 = np.reshape([data2[\"Sell Side Volume LV2\"].to_numpy()], (N2,1)) / avg \n",
    "a4 = np.reshape([data2[\"Buy Side Volume LV2\"].to_numpy()], (N2,1)) / avg \n",
    "a5 = np.reshape([data2[\"Past Move 1\"].to_numpy()], (N2,1)) \n",
    "a6 = np.reshape([data2[\"Past Move 2\"].to_numpy()], (N2,1)) \n",
    "a7 = np.reshape([data2[\"Past Move 3\"].to_numpy()], (N2,1)) \n",
    "a8 = np.reshape([data2[\"Past Move 4\"].to_numpy()], (N2,1)) \n",
    "a9 = np.reshape([data2[\"Past Move 5\"].to_numpy()], (N2,1))\n",
    "X = np.concatenate((a1, a2, a3, a4, a5, a6, a7, a8, a9), axis = 1) \n",
    "final_prediction = np.reshape(np.round(modelfinal.predict(X)).astype(int), (N2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
